{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#######################\n",
    "def batchgen(batchsize):\n",
    "\n",
    "    def getbatch(x,y):\n",
    "        assert (len(x) == len(y)), \"dimension mismatch\"\n",
    "        for i in range(0, len(y), batchsize):\n",
    "            yield x[i:i+batchsize], y[i:i+batchsize],\n",
    "    return getbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vardict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "    def __setattr__(self,name, val):\n",
    "        self[name] = val\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return self.__dict__.items()\n",
    "\n",
    "    def __setstate__(self, items):\n",
    "        for key, val in items:\n",
    "            self.__dict__[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_dict(summary_str, summary_proto = None):\n",
    "    \"convert summary string to a dictionary\"\n",
    "    if summary_proto is None:\n",
    "        summary_proto = tf.Summary()\n",
    "    summary_proto.ParseFromString(summary_str)\n",
    "    summaries = {}\n",
    "    for val in summary_proto.value:\n",
    "        # Assuming all summaries are scalars.\n",
    "        summaries[val.tag] = val.simple_value\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class tflasso():\n",
    "    def __init__(self,\n",
    "             learning_rate = 2e-2,\n",
    "             training_epochs = 5000,\n",
    "                display_step = 100,\n",
    "                BATCH_SIZE = 100,\n",
    "                ALPHA = 1e-4,\n",
    "                NUM_CORES = 3,\n",
    "                checkpoint_dir = \"./checkpoints/\"\n",
    "         ):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.training_epochs=training_epochs\n",
    "        self.display_step = display_step\n",
    "        self.ALPHA = ALPHA\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.NUM_CORES = NUM_CORES  # Choose how many cores to use.\n",
    "        \n",
    "        self.parameters = vardict()\n",
    "#     def __getattr__(self, name):\n",
    "#         return self.parameters[name]\n",
    "    def __getattr__(self, key):\n",
    "        if key.startswith('__') and key.endswith('__'):\n",
    "            return super(tflasso, self).__getattr__(key)\n",
    "        return self.__getitem__(key)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        #if hasattr(self, \"parameters\") and\n",
    "        if key in self.parameters:\n",
    "            return self.parameters[key]\n",
    "        else:\n",
    "            print(key, \"not found\", file = sys.stderr)\n",
    "            return \n",
    "\n",
    "    def _create_network(self):\n",
    "        self.vars = vardict()\n",
    "        self.vars.xx = tf.placeholder(\"float\", shape=[None, self.xlen])\n",
    "        self.vars.yy = tf.placeholder(\"float\", shape=[None, 1])\n",
    "\n",
    "        #def fully_connected():\n",
    "            \n",
    "        # Create Model\n",
    "        self.parameters[\"W1\"] = tf.Variable(tf.truncated_normal([1, self.xlen], stddev=0.1), name=\"weight\")\n",
    "        self.parameters[\"b1\"] = tf.Variable(tf.constant(0.1, shape=[1, 1]), name=\"bias\")\n",
    "        \n",
    "        \n",
    "        self.vars.y_predicted = tf.matmul( self.vars.xx, tf.transpose(self.W1)) + self.b1\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def _create_loss(self):\n",
    "        with tf.name_scope(\"loss\") as scope:\n",
    "            # Minimize the squared errors\n",
    "            l2_loss = tf.reduce_mean(tf.pow( self.vars.y_predicted - self.vars.yy, 2))\n",
    "            l2_sy = tf.scalar_summary( \"L2_loss\", l2_loss )\n",
    "            # Lasso penalty\n",
    "            #l1_penalty =(tf.reduce_sum(tf.abs(self.W1)) +  tf.reduce_sum(tf.abs(self.b1)))/ (1+sum([int(x) for x in self.W1.get_shape()]))\n",
    "            l1_penalty = tf.reduce_sum((tf.abs(tf.concat(1, [self.W1,self.b1]) )) )\n",
    "            l1p_sy =  tf.scalar_summary( \"L1_penalty\" , l1_penalty )\n",
    "            tot_loss = l2_loss + self.ALPHA * l1_penalty\n",
    "            tot_loss_sy =  tf.scalar_summary( \"loss\" , tot_loss )\n",
    "            \n",
    "            _, y_var = tf.nn.moments(self.vars.yy, [0,1])\n",
    "            rsq =  1 - l2_loss / y_var\n",
    "            rsq_sy = tf.scalar_summary( \"R2\", rsq)\n",
    "            \n",
    "        return tot_loss\n",
    "        \n",
    "    def get_params(self, load = True):\n",
    "        params = {}\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            self._create_network()\n",
    "            sess_config = tf.ConfigProto(inter_op_parallelism_threads=self.NUM_CORES,\n",
    "                                       intra_op_parallelism_threads= self.NUM_CORES)\n",
    "            with tf.Session(config = sess_config) as sess:\n",
    "                if load:\n",
    "                    self._load_(sess)\n",
    "                for kk, vv in self.parameters.items():\n",
    "                    params[kk] = vv.eval()\n",
    "        return params\n",
    "        \n",
    "    def _load_(self, sess, checkpoint_dir = None):\n",
    "        if checkpoint_dir:\n",
    "            self.checkpoint_dir = checkpoint_dir\n",
    "        \n",
    "        print(\"loading a session\")\n",
    "        ckpt = tf.train.get_checkpoint_state(self.checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            self.saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        else:\n",
    "            raise Exception(\"no checkpoint found\")\n",
    "        #print( \"loaded b1:\",  self.parameters.b1.name , self.parameters.b1.eval()[0][0]  , sep = \"\\t\" )\n",
    "        assert self.xlen == int(self.vars.xx.get_shape()[1]), \"dimension mismatch\"\n",
    "        return\n",
    "    \n",
    "    def transform(self, X, y = None, load = True):\n",
    "        self.xlen = X.shape[1]\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            self._create_network()\n",
    "            sess_config = tf.ConfigProto(inter_op_parallelism_threads=self.NUM_CORES,\n",
    "                                       intra_op_parallelism_threads= self.NUM_CORES)\n",
    "            with tf.Session(config = sess_config) as sess:\n",
    "                if load:\n",
    "                    self._load_(sess)\n",
    "\n",
    "                y_predicted = sess.run( self.vars.y_predicted,\n",
    "                                feed_dict = { self.vars.xx: X})\n",
    "                if y is not None:\n",
    "                    tot_loss = self._create_loss()\n",
    "                    self.loss = sess.run( tot_loss,\n",
    "                                    feed_dict = { self.vars.xx: X, self.vars.yy :  np.reshape(y, [-1, 1]) })\n",
    "        return y_predicted\n",
    "    \n",
    "    def fit(self, train_X, train_Y , load = True):\n",
    "        #self.X = train_X\n",
    "        self.xlen = train_X.shape[1]\n",
    "        self.r2_progress = []\n",
    "        yvar = train_Y.var()\n",
    "        print(yvar)\n",
    "        # n_samples = y.shape[0]\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            self._create_network()\n",
    "            \n",
    "            tot_loss = self._create_loss()\n",
    "            train_op = tf.train.AdagradOptimizer( self.learning_rate).minimize(tot_loss)\n",
    "            # Merge all the summaries and write them out\n",
    "            summary_op = tf.merge_all_summaries()\n",
    "\n",
    "            # Initializing the variables\n",
    "            init = tf.initialize_all_variables()\n",
    "            \" training per se\"\n",
    "            getb = batchgen( self.BATCH_SIZE)\n",
    "\n",
    "            \n",
    "            # Launch the graph        \n",
    "            sess_config = tf.ConfigProto(inter_op_parallelism_threads=self.NUM_CORES,\n",
    "                                       intra_op_parallelism_threads= self.NUM_CORES)\n",
    "            with tf.Session(config= sess_config) as sess:\n",
    "                sess.run(init)\n",
    "                if load:\n",
    "                    self._load_(sess)\n",
    "                # write summaries out\n",
    "                summary_writer = tf.train.SummaryWriter(\"./tmp/mnist_logs\", sess.graph_def)\n",
    "                summary_proto = tf.Summary()\n",
    "                # Fit all training data\n",
    "                for epoch in range( self.training_epochs):\n",
    "                    \"do minibatches\"\n",
    "                    for (_x_, _y_) in getb(train_X, train_Y):\n",
    "                        _y_ = np.reshape(_y_, [-1, 1])                        \n",
    "                        feed_dict={ self.vars.xx: _x_, self.vars.yy: _y_}\n",
    "                        sess.run(train_op, feed_dict = feed_dict)\n",
    "                    # Display logs once in `display_step` epochs\n",
    "                    if (1+epoch) % self.display_step == 0:\n",
    "                        summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "                        summary_writer.add_summary(summary_str, epoch)\n",
    "                        summary_d = summary_dict(summary_str, summary_proto)\n",
    "                        #print(type(summary_str))\n",
    "                        \n",
    "                        cost = sess.run(tot_loss,\n",
    "                                feed_dict={ self.vars.xx: train_X,\n",
    "                                        self.vars.yy: np.reshape(train_Y, [-1, 1])})\n",
    "                        #rsq = sess.run(rsquared, feed_dict={xx: train_X, yy: np.reshape(train_Y, [-1, 1])})\n",
    "                        rsq =  1 - cost / yvar\n",
    "                        self.r2_progress.append( (epoch, rsq))\n",
    "                        logstr = \"Epoch: {:4d}\\ttot loss= {:.4f}\\tL1 pen= {:.4f}\\tL2 loss= {:.4f}\\tR^2= {:.4f}\".format((epoch+1), \n",
    "                                        summary_d[\"loss\"],summary_d[\"L1_penalty\"],    \n",
    "                                        summary_d[\"L2_loss\"], summary_d[\"R2\"],)\n",
    "                        print(logstr, file = sys.stderr )\n",
    "                        self.saver.save(sess, self.checkpoint_dir +'/' + 'model.ckpt',\n",
    "                           global_step= 1+ epoch)\n",
    "                        #print(\"\\tb1\",  self.parameters.b1.name , self.parameters.b1.eval()[0][0] , sep = \"\\t\")\n",
    "                        #print( \"W=\", sess.run(W1))  # \"b=\", sess.run(b1)\n",
    "                print(\"Optimization Finished!\", file = sys.stderr)\n",
    "#                 print(\"cost = \", sess.run( tot_loss , feed_dict={self.vars.xx: train_X, self.vars.yy: np.reshape(train_Y, [-1, 1]) }) )\n",
    "#                 print(\"W1 = \", sess.run(self.parameters.W1), )\n",
    "#                 print(\"b1 = \", sess.run(self.parameters.b1) )\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/X (Group) ''\n",
      "  children := ['axis0_level0' (VLArray), 'axis0_label0' (Array), 'axis0_level1' (Array), 'axis0_label1' (Array), 'axis1_level1' (Array), 'axis1_label1' (Array), 'block0_items_level0' (VLArray), 'block0_values' (Array), 'block0_items_label0' (Array), 'block0_items_level1' (Array), 'block0_items_label1' (Array), 'axis1_label0' (Array), 'axis1_level0' (Array)], /y (Group) ''\n",
      "  children := ['index_level0' (Array), 'index_label0' (Array), 'index_label1' (Array), 'values' (Array), 'index_level1' (Array)]]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../../data/atac_tss_800_1.h5\"\n",
    "\n",
    "with pd.HDFStore(datafile) as store:\n",
    "    print(store.groups())\n",
    "    y_ = store[\"y\"]\n",
    "    X_ = store[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" transform data \"\"\"\n",
    "sys.path.append(\"..\")\n",
    "from transform_tss import safelog, sumstrands, groupcolumns\n",
    "\n",
    "feature_step = 100\n",
    "select = list(feature_step * np.arange(-2,3,1))\n",
    "\n",
    "Xgr = groupcolumns(X_, step = feature_step, select = select)\n",
    "\n",
    "X, y = safelog(Xgr, y_)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf3 = PolynomialFeatures(degree=3)\n",
    "X3 = pf3.fit_transform(X)\n",
    "trainsamples = 4000\n",
    "train_X, train_Y = X3[:trainsamples], y[:trainsamples].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(pf):\n",
    "    return list(pf._combinations(10, degree=pf.degree,\n",
    "                          interaction_only=pf.interaction_only,\n",
    "                          include_bias = pf.include_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.4581682381\n",
      "loading a session"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  100\ttot loss= 20.5598\tL1 pen= 17.7894\tL2 loss= 17.0020\tR^2= -0.2263\n",
      "Epoch:  200\ttot loss= 19.6631\tL1 pen= 17.5397\tL2 loss= 16.1552\tR^2= -0.1653\n",
      "Epoch:  300\ttot loss= 18.9373\tL1 pen= 17.3073\tL2 loss= 15.4758\tR^2= -0.1163\n",
      "Epoch:  400\ttot loss= 18.3466\tL1 pen= 17.1014\tL2 loss= 14.9263\tR^2= -0.0766\n",
      "Epoch:  500\ttot loss= 17.8490\tL1 pen= 16.9095\tL2 loss= 14.4671\tR^2= -0.0435\n",
      "Epoch:  600\ttot loss= 17.4279\tL1 pen= 16.7294\tL2 loss= 14.0820\tR^2= -0.0157\n",
      "Epoch:  700\ttot loss= 17.0645\tL1 pen= 16.5552\tL2 loss= 13.7535\tR^2= 0.0080\n",
      "Epoch:  800\ttot loss= 16.7412\tL1 pen= 16.3860\tL2 loss= 13.4640\tR^2= 0.0288\n",
      "Epoch:  900\ttot loss= 16.4587\tL1 pen= 16.2396\tL2 loss= 13.2108\tR^2= 0.0471\n",
      "Epoch: 1000\ttot loss= 16.2122\tL1 pen= 16.0969\tL2 loss= 12.9928\tR^2= 0.0628"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2d632938e8ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mALPHA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2e-1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./cubiclasso/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtfl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-fb7514546665>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_X, train_Y, load)\u001b[0m\n\u001b[0;32m    152\u001b[0m                         \u001b[0m_y_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_y_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_x_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_y_\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                     \u001b[1;31m# Display logs once in `display_step` epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 428\u001b[1;33m                                target_list)\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tfl = tflasso(ALPHA = 2e-1, checkpoint_dir = \"./cubiclasso/\")\n",
    "tfl.fit( train_X, train_Y , load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f983c0b74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts, r2s = list(zip( *tfl.r2_progress ))\n",
    "plt.plot(ts, r2s)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"R^2\")\n",
    "plt.ylim([0, 0.1* np.ceil(10*max(r2s))])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X, test_Y = X3[trainsamples:], y[trainsamples:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading a session\n",
      "13.0988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20946671081424684"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfl = tflasso(checkpoint_dir = \"./cubiclasso/\")\n",
    "tfl.transform( test_X, test_Y, load = True)\n",
    "\n",
    "print( tfl.loss )\n",
    "r2 = 1- tfl.loss/test_Y.var()\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf3.powers_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "ncoef = len(W1)\n",
    "xlabels = np.array( get_labels(pf3) )\n",
    "\n",
    "forder = np.array([len(x) for x in xlabels])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3,figsize = (14, 5))\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "for nn in range(3):\n",
    "    valid =( forder == (nn+1))\n",
    "    print(sum(valid))\n",
    "    x_ =  np.arange(ncoef)[valid]\n",
    "    y_ = np.log10( abs(W1[valid]) )\n",
    "    axs[nn].scatter(x_, y_ )\n",
    "    axs[nn].scatter( x_[y_>-3], y_[y_>-3], 25, \"r\" )\n",
    "    #axs[nn].stem( x_[y_>-3], y_[y_>-3], markerfmt = \"ro\" )\n",
    "    if nn < 2:\n",
    "        axs[nn].set_xticks(x_ )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid]], rotation = 90)\n",
    "    else:\n",
    "        axs[nn].set_xticks(x_[::4] )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid][::4]], rotation = 90)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "print(len(W1))\n",
    "plt.stem( np.arange(len(W1)), np.log10( abs(W1)) )\n",
    "plt.stem( np.arange(len(W1))[np.log10(W1)>-3], np.log10(W1)[np.log10(W1)>-3], markerfmt = \"ro\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
