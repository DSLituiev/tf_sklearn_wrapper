{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#######################\n",
    "def batchgen(batchsize):\n",
    "\n",
    "    def getbatch(x,y):\n",
    "        assert (len(x) == len(y)), \"dimension mismatch\"\n",
    "        for i in range(0, len(y), batchsize):\n",
    "            yield x[i:i+batchsize], y[i:i+batchsize],\n",
    "    return getbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vardict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "    def __setattr__(self,name, val):\n",
    "        self[name] = val\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return self.__dict__.items()\n",
    "\n",
    "    def __setstate__(self, items):\n",
    "        for key, val in items:\n",
    "            self.__dict__[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_dict(summary_str, summary_proto = None):\n",
    "    \"convert summary string to a dictionary\"\n",
    "    if summary_proto is None:\n",
    "        summary_proto = tf.Summary()\n",
    "    summary_proto.ParseFromString(summary_str)\n",
    "    summaries = {}\n",
    "    for val in summary_proto.value:\n",
    "        # Assuming all summaries are scalars.\n",
    "        summaries[val.tag] = val.simple_value\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tflearn import tflearn\n",
    "\n",
    "class tflasso(tflearn):\n",
    "    def _create_network(self):\n",
    "        self.vars = vardict()\n",
    "        self.vars.xx = tf.placeholder(\"float\", shape=[None, self.xlen])\n",
    "        self.vars.yy = tf.placeholder(\"float\", shape=[None, 1])\n",
    "\n",
    "        #def fully_connected():\n",
    "            \n",
    "        # Create Model\n",
    "        self.parameters[\"W1\"] = tf.Variable(tf.truncated_normal([1, self.xlen], stddev=0.1), name=\"weight\")\n",
    "        self.parameters[\"b1\"] = tf.Variable(tf.constant(0.1, shape=[1, 1]), name=\"bias\")\n",
    "        \n",
    "        \n",
    "        self.vars.y_predicted = tf.matmul( self.vars.xx, tf.transpose(self.W1)) + self.b1\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/X (Group) ''\n",
      "  children := ['axis1_label1' (Array), 'axis1_label0' (Array), 'block0_items_label1' (Array), 'axis0_level1' (Array), 'block0_items_level1' (Array), 'axis0_label1' (Array), 'block0_items_label0' (Array), 'axis0_level0' (VLArray), 'block0_items_level0' (VLArray), 'axis1_level1' (Array), 'axis0_label0' (Array), 'block0_values' (Array), 'axis1_level0' (Array)], /y (Group) ''\n",
      "  children := ['index_level1' (Array), 'index_level0' (Array), 'values' (Array), 'index_label1' (Array), 'index_label0' (Array)]]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../../data/atac_tss_800_1.h5\"\n",
    "\n",
    "with pd.HDFStore(datafile) as store:\n",
    "    print(store.groups())\n",
    "    y_ = store[\"y\"]\n",
    "    X_ = store[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" transform data \"\"\"\n",
    "sys.path.append(\"..\")\n",
    "from transform_tss import safelog, sumstrands, groupcolumns\n",
    "\n",
    "feature_step = 100\n",
    "select = list(feature_step * np.arange(-2,3,1))\n",
    "\n",
    "Xgr = groupcolumns(X_, step = feature_step, select = select)\n",
    "\n",
    "X, y = safelog(Xgr, y_)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf3 = PolynomialFeatures(degree=3)\n",
    "X3 = pf3.fit_transform(X)\n",
    "trainsamples = 4000\n",
    "train_X, train_Y = X3[:trainsamples], y[:trainsamples].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(pf):\n",
    "    return list(pf._combinations(10, degree=pf.degree,\n",
    "                          interaction_only=pf.interaction_only,\n",
    "                          include_bias = pf.include_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading a session\n",
      "training epochs: 2800 ... 7800, saving each 100' epoch\n",
      "Epoch: 2801\ttot loss= 11.4907\tL2 loss= 11.4907\tR^2= 0.3418\n",
      "Epoch: 2901\ttot loss= 11.4585\tL2 loss= 11.4585\tR^2= 0.3437\n",
      "Epoch: 3001\ttot loss= 11.4280\tL2 loss= 11.4280\tR^2= 0.3454\n",
      "Epoch: 3101\ttot loss= 11.3988\tL2 loss= 11.3988\tR^2= 0.3471\n",
      "Epoch: 3201\ttot loss= 11.3711\tL2 loss= 11.3711\tR^2= 0.3487\n",
      "Epoch: 3301\ttot loss= 11.3445\tL2 loss= 11.3445\tR^2= 0.3502\n",
      "Epoch: 3401\ttot loss= 11.3192\tL2 loss= 11.3192\tR^2= 0.3516\n",
      "Epoch: 3501\ttot loss= 11.2949\tL2 loss= 11.2949\tR^2= 0.3530\n",
      "Epoch: 3601\ttot loss= 11.2716\tL2 loss= 11.2716\tR^2= 0.3544\n",
      "Epoch: 3701\ttot loss= 11.2493\tL2 loss= 11.2493\tR^2= 0.3556\n",
      "Epoch: 3801\ttot loss= 11.2278\tL2 loss= 11.2278\tR^2= 0.3569\n",
      "Epoch: 3901\ttot loss= 11.2072\tL2 loss= 11.2072\tR^2= 0.3581\n",
      "Epoch: 4001\ttot loss= 11.1874\tL2 loss= 11.1874\tR^2= 0.3592\n",
      "Epoch: 4101\ttot loss= 11.1683\tL2 loss= 11.1683\tR^2= 0.3603\n",
      "Epoch: 4201\ttot loss= 11.1499\tL2 loss= 11.1499\tR^2= 0.3613\n",
      "Epoch: 4301\ttot loss= 11.1321\tL2 loss= 11.1321\tR^2= 0.3624\n",
      "Epoch: 4401\ttot loss= 11.1150\tL2 loss= 11.1150\tR^2= 0.3633\n",
      "Epoch: 4501\ttot loss= 11.0984\tL2 loss= 11.0984\tR^2= 0.3643\n",
      "Epoch: 4601\ttot loss= 11.0823\tL2 loss= 11.0823\tR^2= 0.3652\n",
      "Epoch: 4701\ttot loss= 11.0668\tL2 loss= 11.0668\tR^2= 0.3661\n",
      "Epoch: 4801\ttot loss= 11.0518\tL2 loss= 11.0518\tR^2= 0.3670\n",
      "Epoch: 4901\ttot loss= 11.0372\tL2 loss= 11.0372\tR^2= 0.3678\n",
      "Epoch: 5001\ttot loss= 11.0231\tL2 loss= 11.0231\tR^2= 0.3686\n",
      "Epoch: 5101\ttot loss= 11.0094\tL2 loss= 11.0094\tR^2= 0.3694\n",
      "Epoch: 5201\ttot loss= 10.9961\tL2 loss= 10.9961\tR^2= 0.3701\n",
      "Epoch: 5301\ttot loss= 10.9832\tL2 loss= 10.9832\tR^2= 0.3709\n",
      "Epoch: 5401\ttot loss= 10.9706\tL2 loss= 10.9706\tR^2= 0.3716\n",
      " 24%|██▍       | 24/100 [00:01<00:03, 20.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.4581682381\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6589692b1f4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mALPHA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2e-1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./cubiclasso/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtfl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/dima/data/repos/qtl_atac_rna/skl_pipeline/src/tfregression/tflearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_X, train_Y, test_X, test_Y, load)\u001b[0m\n\u001b[0;32m    211\u001b[0m                             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                                 \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_x_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_y_\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                     \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmacro_epoch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[1;31m# Display logs once in `display_step` epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 428\u001b[1;33m                                target_list)\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tfl = tflasso(ALPHA = 2e-1, checkpoint_dir = \"./cubiclasso/\", dropout = None)\n",
    "tfl.fit( train_X, train_Y , load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r2_progress not found\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type object argument after * must be a sequence, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5971624c9c1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtfl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr2_progress\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R^2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: type object argument after * must be a sequence, not NoneType"
     ]
    }
   ],
   "source": [
    "ts, r2s = list(zip( *tfl.r2_progress ))\n",
    "plt.plot(ts, r2s)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"R^2\")\n",
    "plt.ylim([0, 0.1* np.ceil(10*max(r2s))])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X, test_Y = X3[trainsamples:], y[trainsamples:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading a session\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None of None has invalid type <class 'NoneType'>, must be a string or Tensor. (Can not convert a NoneType into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    321\u001b[0m           fetch_t = self.graph.as_graph_element(subfetch, allow_tensor=True,\n\u001b[1;32m--> 322\u001b[1;33m                                                 allow_operation=True)\n\u001b[0m\u001b[0;32m    323\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[1;32m-> 1960\u001b[1;33m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a NoneType into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-02a78c0cb4ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./cubiclasso/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtfl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtfl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtfl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dima/data/repos/qtl_atac_rna/skl_pipeline/src/tfregression/tflearn.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, load)\u001b[0m\n\u001b[0;32m    160\u001b[0m                                 feed_dict = feed_dict )\n\u001b[0;32m    161\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                     \u001b[0msummary_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m                     \u001b[0msummary_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0msummary_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummary_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary_proto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    328\u001b[0m           raise TypeError('Fetch argument %r of %r has invalid type %r, '\n\u001b[0;32m    329\u001b[0m                           \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                           % (subfetch, fetch, type(subfetch), str(e)))\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m           raise ValueError('Fetch argument %r of %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument None of None has invalid type <class 'NoneType'>, must be a string or Tensor. (Can not convert a NoneType into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "tfl = tflasso(checkpoint_dir = \"./cubiclasso/\", dropout = False)\n",
    "tfl.transform( test_X, test_Y, load = True)\n",
    "\n",
    "print( tfl.loss )\n",
    "r2 = 1- tfl.loss/test_Y.var()\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf3.powers_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "ncoef = len(W1)\n",
    "xlabels = np.array( get_labels(pf3) )\n",
    "\n",
    "forder = np.array([len(x) for x in xlabels])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3,figsize = (14, 5))\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "for nn in range(3):\n",
    "    valid =( forder == (nn+1))\n",
    "    print(sum(valid))\n",
    "    x_ =  np.arange(ncoef)[valid]\n",
    "    y_ = np.log10( abs(W1[valid]) )\n",
    "    axs[nn].scatter(x_, y_ )\n",
    "    axs[nn].scatter( x_[y_>-3], y_[y_>-3], 25, \"r\" )\n",
    "    #axs[nn].stem( x_[y_>-3], y_[y_>-3], markerfmt = \"ro\" )\n",
    "    if nn < 2:\n",
    "        axs[nn].set_xticks(x_ )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid]], rotation = 90)\n",
    "    else:\n",
    "        axs[nn].set_xticks(x_[::4] )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid][::4]], rotation = 90)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "print(len(W1))\n",
    "plt.stem( np.arange(len(W1)), np.log10( abs(W1)) )\n",
    "plt.stem( np.arange(len(W1))[np.log10(W1)>-3], np.log10(W1)[np.log10(W1)>-3], markerfmt = \"ro\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
