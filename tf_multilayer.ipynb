{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer)\n",
    "    return var\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "    Note that the Variable is initialized with a truncated normal distribution.\n",
    "    A weight decay is added only if one is specified.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    var = _variable_on_cpu(name, shape,\n",
    "                         tf.truncated_normal_initializer(stddev=stddev))\n",
    "    if wd:\n",
    "        weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tflearn import tflearn, vardict\n",
    "\n",
    "class tflasso(tflearn):\n",
    "    def _create_network(self):\n",
    "        self.vars = vardict()\n",
    "        self.vars.xx = tf.placeholder(\"float\", shape=[None, self.xlen])\n",
    "        self.vars.yy = tf.placeholder(\"float\", shape=[None, 1])\n",
    "\n",
    "        #def fully_connected():\n",
    "            \n",
    "        # Create Model\n",
    "        x_images = tf.reshape(self.vars.xx, [-1, 1, self.xlen//2,2])\n",
    "        # print(\"x_images\", x_images.get_shape())\n",
    "        \n",
    "        with tf.variable_scope('conv1') as scope:\n",
    "            self.parameters.c1_kernel = _variable_with_weight_decay('weights', shape=[1, 5, 2, 64],\n",
    "                                                 stddev=1e-4, wd=0.0)\n",
    "            conv = tf.nn.conv2d(x_images, self.parameters.c1_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "            bias = tf.nn.bias_add(conv, biases)\n",
    "            conv1 = tf.nn.relu(bias, name=scope.name)\n",
    "            #_activation_summary(conv1)\n",
    "        \n",
    "        # pool1\n",
    "        pool1 = tf.nn.max_pool(conv1, ksize=[1, 1, 3, 1], strides=[1, 1, 2, 1],\n",
    "                                 padding='SAME', name='pool1')\n",
    "        # norm1\n",
    "        norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha= 0.001 / 9.0, beta=0.75,\n",
    "                            name='norm1')\n",
    "        # conv2\n",
    "        with tf.variable_scope('conv2') as scope:\n",
    "            self.parameters.c2_kernel = _variable_with_weight_decay('weights', shape=[1, 5, 64, 64],\n",
    "                                                 stddev=1e-4, wd=0.0)\n",
    "            conv = tf.nn.conv2d(norm1, self.parameters.c2_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "            bias = tf.nn.bias_add(conv, biases)\n",
    "            conv2 = tf.nn.relu(bias, name=scope.name)\n",
    "            #_activation_summary(conv2)\n",
    "        # norm2\n",
    "        norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                            name='norm2')\n",
    "        # pool2\n",
    "        pool2 = tf.nn.max_pool(norm2, ksize=[1, 1, 3, 1],\n",
    "                                strides=[1, 1, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "        # local3\n",
    "        with tf.variable_scope('local3') as scope:\n",
    "            # Move everything into depth so we can perform a single matrix multiply.\n",
    "            dim = 1\n",
    "            for d in pool2.get_shape()[1:].as_list():\n",
    "                dim *= d\n",
    "            reshape = tf.reshape(pool2, [-1, dim])\n",
    "            self.parameters.l1_weights = _variable_with_weight_decay('weights', shape=[dim, self.xlen],\n",
    "                                                  stddev=0.04, wd=0.004)\n",
    "            self.parameters.l1_biases = _variable_on_cpu('biases', [self.xlen], tf.constant_initializer(0.1))\n",
    "            local3 = tf.nn.relu_layer(reshape, self.parameters.l1_weights, \n",
    "                                      self.parameters.l1_biases, name=scope.name)\n",
    "            #_activation_summary(local3)\n",
    "            \n",
    "        if self.train:\n",
    "            self.vars.keep_prob = tf.placeholder(\"float\")\n",
    "            local3 = tf.nn.dropout(local3, self.vars.keep_prob)\n",
    "        \n",
    "        # local4\n",
    "        with tf.variable_scope('local4') as scope:\n",
    "            self.parameters.l2_weights = _variable_with_weight_decay('weights', shape=[self.xlen, 1],\n",
    "                                                  stddev=0.04, wd=0.004)\n",
    "            self.parameters.l2_biases = _variable_on_cpu('biases', [1], tf.constant_initializer(0.1))\n",
    "            \n",
    "            self.vars.y_predicted = tf.nn.relu_layer(local3, self.parameters.l2_weights,\n",
    "                                                     self.parameters.l2_biases, name=scope.name)\n",
    "            #_activation_summary(local4)\n",
    "\n",
    "#         self.parameters[\"W1\"] = tf.Variable(tf.truncated_normal([1, self.xlen], stddev=0.1), name=\"weight\")\n",
    "#         self.parameters[\"b1\"] = tf.Variable(tf.constant(0.1, shape=[1, 1]), name=\"bias\")\n",
    "        \n",
    "        #self.vars.y_predicted = tf.matmul( self.vars.xx, tf.transpose(self.W1)) + self.b1\n",
    "        self.saver = tf.train.Saver()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/X (Group) ''\n",
      "  children := ['axis0_label1' (Array), 'axis0_level0' (VLArray), 'block0_items_level0' (VLArray), 'axis1_level0' (Array), 'axis0_level1' (Array), 'axis1_level1' (Array), 'block0_values' (Array), 'block0_items_level1' (Array), 'block0_items_label1' (Array), 'block0_items_label0' (Array), 'axis1_label0' (Array), 'axis0_label0' (Array), 'axis1_label1' (Array)], /y (Group) ''\n",
      "  children := ['index_label1' (Array), 'index_level1' (Array), 'index_label0' (Array), 'values' (Array), 'index_level0' (Array)]]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../../data/atac_tss_800_1.h5\"\n",
    "\n",
    "with pd.HDFStore(datafile) as store:\n",
    "    print(store.groups())\n",
    "    y_ = store[\"y\"]\n",
    "    X_ = store[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41881, 322)\n",
      "(4000, 322)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" transform data \"\"\"\n",
    "sys.path.append(\"..\")\n",
    "from transform_tss import safelog, sumstrands, groupcolumns\n",
    "\n",
    "feature_step = 10\n",
    "select = None# list(feature_step * np.arange(-2,3,1))\n",
    "\n",
    "Xgr = groupcolumns(X_, step = feature_step, select = select)\n",
    "print(Xgr.shape)\n",
    "# print(Xgr.head(3))\n",
    "X, y = safelog(Xgr, y_, pseudocount=1/32)\n",
    "\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#pf3 = PolynomialFeatures(degree=3)\n",
    "#X3 = pf3.fit_transform(X)\n",
    "trainsamples = 4000\n",
    "train_X, train_Y = X[:trainsamples], y[:trainsamples].as_matrix()\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(pf):\n",
    "    return list(pf._combinations(10, degree=pf.degree,\n",
    "                          interaction_only=pf.interaction_only,\n",
    "                          include_bias = pf.include_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mcheckpoint\u001b[0m*      \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-301\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-451\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-1\u001b[0m*    \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-351\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-501\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-101\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-401\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-51\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls ./cnn_ckpt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading a session\n",
      "  1%|          | 39/5000 [06:49<14:27:38,  0.10it/s]"
     ]
    }
   ],
   "source": [
    "tfl = tflasso(ALPHA = 2e-1, display_step = 50, BATCH_SIZE = 50,\n",
    "             learning_rate = 5e-3, checkpoint_dir = \"./cnn_ckpt/\")\n",
    "tfl.fit( train_X, train_Y , load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFNtJREFUeJzt3X+QXWd93/H3RysZW5Z/lEIgsd2IFCXFNASTQVH4lUtw\nQc4kiDZpbENSJulQt41DOk2pIobW205nUnemgaZMQEkcxiUZ1AEcI6aAKSk3Exh+WOAfBCTHInjG\nMsQBktjINljSfvvHPbJu9lmt7q72aFfX79fMGZ3znGePvo/26n72PGfPuakqJEkat261C5AkrT2G\ngySpYThIkhqGgySpYThIkhqGgySp0Ws4JNme5ECSe5PsXGD/v0tyR7d8IcnRJBf3WZMk6dTS130O\nSWaAe4ArgQeA24Frq2r/Sfr/JPBvqurKXgqSJE2szzOHrcDBqrqvqo4Ae4Adi/R/LfCeHuuRJE2o\nz3C4BLh/bPtQ19ZIshF4FfD+HuuRJE2oz3BYynzVTwGfqKq/6asYSdLk1vd47AeAy8a2L2N09rCQ\na1hkSimJD4CSpGWoqizn6/o8c9gHbEmyOck5wNXA3vmdklwEvAz4wGIHq6qpXW644YZVr8HxOTbH\nN33L6ejtzKGqjia5HrgNmAFuqqr9Sa7r9u/uur4GuK2qHuurFknS0vQ5rURVfRj48Ly23fO2bwZu\n7rMOSdLSeIf0GjAYDFa7hF5N8/imeWzg+J7MersJbiUlqbOhTklaS5JQa/CCtCTpLGU4SJIahoMk\nqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4\nSJIahoMkqWE4SJIahoMkqWE4SJIa61e7AElrUxUcO3ZiverE+qR/LvVr1q+H88+HmZmVHYuWrtdw\nSLIdeBswA/xuVd24QJ8B8FZgA/CNqhr0WZO0mGPH4MiR0fL44yfWF1oef/zEm+e4ZHltk/SZm4Pv\nfOfE8u1v97f9+OOjv/94DfPXJ/1zKX2PHIFHH4VzzhmFxPiyadOp207VZ+NGWDfhfEkVHD168u/9\nYq+Nky1Hj558OdX+5SynI3U8sldYkhngHuBK4AHgduDaqto/1udi4JPAq6rqUJKnVdU3FjhW9VXn\najl2DA4fhocfHr0ojh0b/cefm/vb6/O3l9NvfPvYsdGyEi/OSfvD6D/+unUn3iwW2l6JPnCitkne\n3Oe3AWzYMHpz2rDh5Mvx/TMz7Rv4/JfqQi/d5fQ5/u/4lKeMlnPPPbE+yfZyvmbSN9KVVAWPPQaP\nPPK3l8OHT912qj6PPQbnnXciLNatW/yNfGbm5N/75S7r1y++TNJn0uW5zw1VtcCPHafW55nDVuBg\nVd0HkGQPsAPYP9bntcD7q+oQwELBsNbMzZ14U3/4YXjooYXXT7XvkUdGL84LLxy92NatG70Q161r\n15e772T9TvXC3Lhx8hffqV7Ix6cHjk8xzM2dWF9o+3T7wOjvnfTNff7idMbqS0avwY0b4elPX9lj\nz82NAuJ4YMzNLf46Wehs7smiz3C4BLh/bPsQ8CPz+mwBNiT5OHAB8D+q6t091nRKN98Mn/jEyd/Y\nDx8evWgvvHC0XHTRwuuXXgqXX37yfps2rc5PZdKT2bp1J84atLg+w2GSeaANwAuAVwAbgU8l+XRV\n3Tu/4+zs7BPrg8GAwWCwMlXO813fBS984cnf9C+4wJ8uJa1Nw+GQ4XC4Isfq85rDNmC2qrZ327uA\nufGL0kl2AudV1Wy3/bvAR6rqffOONXXXHCSpb8nyrzn0ObGxD9iSZHOSc4Crgb3z+nwAeEmSmSQb\nGU07fanHmiRJE+htWqmqjia5HriN0a+y3lRV+5Nc1+3fXVUHknwEuBuYA36nqgwHSVplvU0rrSSn\nlSRp6dbqtJIk6SxlOEiSGoaDJKlhOEiSGoaDJKlhOEiSGoaDJKlhOEiSGoaDJKlhOEiSGoaDJKlh\nOEiSGoaDJKlhOEiSGoaDJKlhOEiSGoaDJKlhOEiSGoaDJKlhOEiSGoaDJKlhOEiSGoaDJKnRazgk\n2Z7kQJJ7k+xcYP8gyUNJ7uiWt/RZjyRpMuv7OnCSGeDtwJXAA8DtSfZW1f55Xf+4ql7dVx2SpKXr\n88xhK3Cwqu6rqiPAHmDHAv3SYw2SpGXoMxwuAe4f2z7UtY0r4EVJ7kryoSSX91iPJGlCvU0rMXrj\nP5XPA5dV1aNJrgJuBb5/oY6zs7NPrA8GAwaDwQqUKEnTYzgcMhwOV+RYqZrkPXwZB062AbNVtb3b\n3gXMVdWNi3zNV4Afrqq/mtdefdUpSdMqCVW1rKn7PqeV9gFbkmxOcg5wNbB3vEOSZyRJt76VUVj9\nVXsoSdKZ1Nu0UlUdTXI9cBswA9xUVfuTXNft3w38DPCvkhwFHgWu6aseSdLkeptWWklOK0nS0q3V\naSVJ0lnKcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwH\nSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVKj13BIsj3JgST3\nJtm5SL8XJjma5J/0WY8kaTK9hUOSGeDtwHbgcuDaJM85Sb8bgY8A6aseSdLk+jxz2AocrKr7quoI\nsAfYsUC/XwbeB3y9x1okSUvQZzhcAtw/tn2oa3tCkksYBcY7uqbqsR5J0oTW93jsSd7o3wb8WlVV\nkrDItNLs7OwT64PBgMFgcLr1SdJUGQ6HDIfDFTlWqvr5YT3JNmC2qrZ327uAuaq6cazPn3MiEJ4G\nPAq8oar2zjtW9VWnJE2rJFTVsq7l9hkO64F7gFcAXwU+C1xbVftP0v9dwAer6pYF9hkOkrREpxMO\nvU0rVdXRJNcDtwEzwE1VtT/Jdd3+3X393ZKk09PbmcNK8sxBkpbudM4cvENaktQwHCRJDcNBktQ4\naTgkWZ/kXyb5L0lePG/fW/ovTZK0WhY7c9gNvAz4JvCbSX5jbN9P91qVJGlVLRYOW6vqtVX1VmAb\ncEGSW5Kce4ZqkyStksXCYcPxlao6UlVvAO4C/gjY1HdhkqTVs1g4fC7JVeMNVfWfgHcBm/ssSpK0\nurwJTpKmVK83wXXPSJIkPYksGg5JLgA+cIZqkSStEYvd5/DdjC4+//aZK0eStBac9JpDki8Db1ro\nEdpnmtccJGnp+rrm8NfM+1hPSdKTw2LhMACuSvJLZ6gWSdIacdJwqKrDwKuBK85cOZKktcD7HCRp\nSp3RD/vJyNXL+cskSWeHxX6VdVOSX03yW0n+dZJ1Sf4x8EXgdWeuREnSmbbYr7LeAjwMfAp4JXAZ\n8G3gjVV15xmrEKeVJGk5TmdaabFwuLuqntetzwBfA763qh5bdqXLZDhI0tL1dc3h2PGVqjoGPLAa\nwSBJOvMWO3M4Bjw61nQecDwcqqou7Lm28Vo8c5CkJerlzKGqZqrqgrFl/dj6RMGQZHuSA0nuTbJz\ngf07ktyV5I4kn0vy48sZhCRpZfV2n0N3neIe4ErgAeB24Nqq2j/W5/yqeqRb/0HgD6vq2QscyzMH\nSVqiM3qfwxJsBQ5W1X1VdQTYA+wY73A8GDqbgG/0WI8kaUJ9hsMlwP1j24dY4EF+SV6TZD/wYeCN\nPdYjSZpQn5/yNtE8UFXdCtya5KXAu4EfWKjf7OzsE+uDwYDBYHD6FUrSFBkOhwyHwxU5Vp/XHLYB\ns1W1vdveBcxV1Y2LfM2Xga1V9c157V5zkKQlWqvXHPYBW5JsTnIOcDWwd7xDkr+fJN36CwDmB4Mk\n6czrbVqpqo4muR64DZgBbqqq/Umu6/bvBn4a+GdJjgCHgWv6qkeSNDkf2S1JU2qtTitJks5ShoMk\nqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4\nSJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIahoMkqWE4SJIavYdDku1JDiS5N8nOBfa/Lsld\nSe5O8skkz+u7JknS4lJV/R08mQHuAa4EHgBuB66tqv1jfX4U+FJVPZRkOzBbVdvmHaf6rFOSplES\nqirL+dq+zxy2Ager6r6qOgLsAXaMd6iqT1XVQ93mZ4BLe65JknQKfYfDJcD9Y9uHuraT+efAh3qt\nSJJ0Sut7Pv7Ec0FJXg78IvDihfbPzs4+sT4YDBgMBqdZmiRNl+FwyHA4XJFj9X3NYRujawjbu+1d\nwFxV3Tiv3/OAW4DtVXVwgeN4zUGSlmgtX3PYB2xJsjnJOcDVwN7xDkn+HqNg+LmFgkGSdOb1Oq1U\nVUeTXA/cBswAN1XV/iTXdft3A/8R+DvAO5IAHKmqrX3WJUlaXK/TSivFaSVJWrq1PK0kSToLGQ6S\npIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbh\nIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElq9B4OSbYnOZDk3iQ7F9j/D5J8\nKsm3k/xq3/VIkk5tfZ8HTzIDvB24EngAuD3J3qraP9btm8AvA6/psxZJ0uT6PnPYChysqvuq6giw\nB9gx3qGqvl5V+4AjPdciSZpQ3+FwCXD/2Pahrk2StIb1Oq0E1EodaHZ29on1wWDAYDBYqUNL0lQY\nDocMh8MVOVaqVuz9uz14sg2Yrart3fYuYK6qblyg7w3A4ar67wvsqz7rlKRplISqynK+tu9ppX3A\nliSbk5wDXA3sPUnfZQ1AkrTyej1zAEhyFfA2YAa4qap+Pcl1AFW1O8kzgduBC4E54FvA5VV1eOwY\nnjlI0hKdzplD7+GwEgwHSVq6tTytJEk6CxkOkqSG4SBJahgOkqSG4SBJahgOkqSG4SBJahgOkqSG\n4SBJahgOkqSG4SBJahgOkqSG4SBJahgOkqSG4SBJahgOkqSG4SBJahgOkqSG4SBJahgOkqSG4SBJ\nahgOkqRGr+GQZHuSA0nuTbLzJH1+s9t/V5Ir+qxHkjSZ3sIhyQzwdmA7cDlwbZLnzOvzE8Czq2oL\n8C+Ad/RVz1o2HA5Xu4ReTfP4pnls4PiezPo8c9gKHKyq+6rqCLAH2DGvz6uBmwGq6jPAxUme0WNN\na9K0v0CneXzTPDZwfE9mfYbDJcD9Y9uHurZT9bm0x5okSRPoMxxqwn5Z5tdJknqSqn7ei5NsA2ar\nanu3vQuYq6obx/q8ExhW1Z5u+wDwY1X14LxjGRiStAxVNf8H8ImsX+lCxuwDtiTZDHwVuBq4dl6f\nvcD1wJ4uTP5mfjDA8gcnSVqe3sKhqo4muR64DZgBbqqq/Umu6/bvrqoPJfmJJAeBR4Bf6KseSdLk\neptWkiSdvVb9Dukkv5fkwSRfGGt7apL/m+TPknw0ycVj+3Z1N80dSPLK1al6ckkuS/LxJF9M8qdJ\n3ti1T8UYk5yb5DNJ7kzypSS/3rVPxfhgdM9OkjuSfLDbnqax3Zfk7m58n+3apml8Fyd5X5L93evz\nR6ZlfEl+oPu+HV8eSvLGFRtfVa3qArwUuAL4wljbfwP+fbe+E/iv3frlwJ3ABmAzcBBYt9pjOMX4\nngk8v1vfBNwDPGfKxrix+3M98GngJVM2vn8L/AGwdwpfn18BnjqvbZrGdzPwi2Ovz4umaXxj41wH\nfA24bKXGt+qD6orePC8cDgDP6NafCRzo1ncBO8f6fQTYttr1L3GstwJXTuMYgY3A7cBzp2V8jO67\n+RjwcuCDXdtUjK2r8SvA353XNhXj64Lgzxdon4rxzRvTK4E/Wcnxrfq00kk8o0781tKDwPG7pr+H\n0Y1yxy10Y92a1f3m1hXAZ5iiMSZZl+RORuP4eFV9kekZ31uBNwFzY23TMjYY3Vf0sST7kryha5uW\n8T0L+HqSdyX5fJLfSXI+0zO+cdcA7+nWV2R8azUcnlCjiFvsqvlZcUU9ySbg/cCvVNW3xved7WOs\nqrmqej6jn7JfluTl8/afleNL8pPAX1bVHbQ3awJn79jGvLiqrgCuAn4pyUvHd57l41sPvAD4rap6\nAaPfiPy18Q5n+fgASHIO8FPAe+fvO53xrdVweDDJMwGSfDfwl137A4zm1I67tGtb05JsYBQM766q\nW7vmqRojQFU9BPwf4IeZjvG9CHh1kq8w+qnsx5O8m+kYGwBV9bXuz68Df8jomWjTMr5DwKGqur3b\nfh+jsPiLKRnfcVcBn+u+h7BC37+1Gg57gdd3669nNE9/vP2aJOckeRawBfjsKtQ3sSQBbgK+VFVv\nG9s1FWNM8rTjvw2R5DzgHwF3MAXjq6o3V9VlVfUsRqft/6+qfp4pGBtAko1JLujWz2c0b/0FpmR8\nVfUXwP1Jvr9ruhL4IvBBpmB8Y67lxJQSrNT3bw1cSHkPozuoH2f0EL5fAJ7K6CLgnwEfBS4e6/9m\nRlfZDwCvWu36JxjfSxjNV9/J6E3zDkaPMZ+KMQI/CHy+G9/dwJu69qkY31jNP8aJ31aairExmpO/\ns1v+FNg1TePr6v0hRr8kcRdwC6OL1NM0vvOBbwAXjLWtyPi8CU6S1Fir00qSpFVkOEiSGoaDJKlh\nOEiSGoaDJKlhOEiSGoaD1LMkg+OP+5bOFoaDJKlhOEidJD/XfXDRHUne2X3Iz+Ekv5HRBzV9LMnT\nur7PT/LpJHcluWXsESLP7vrdmeRzSb6P0cPNNiV5b/ehM7+/muOUJmE4SECS5wA/C7yoRk8pPQa8\nju4zKqrqHwJ/DNzQfcn/YvSokB9i9Dyi4+1/APzPGj2l9kcZfQBLGD2q/VcYfeDK9yV58RkZmLRM\n61e7AGmNeAWjp8nuGz0rkXMZPc1yDvjfXZ/fB25JciFwUVX9Sdd+M/De7rHs31NVHwCoqscBuuN9\ntqq+2m3fyegDrj7Z/7Ck5TEcpBNurqo3jzck+Q/jmyz8/PsFP+thnu+MrR/D/3ta45xWkkb+CPiZ\nJE8H6D6k/XsZ/R/5p12f1zL6KMaHgb9O8pKu/eeBYVUdBg4l2dEd4yndY8yls44/vUhAVe1P8hbg\no0nWMXqE/PWMPj1sa7fvQeDq7kteD7wzyUbgy4weNQ+joNid5D93x/hZRmcb8884fByy1jQf2S0t\nIsm3quqC1a5DOtOcVpIW509PelLyzEGS1PDMQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSY3/D7B7\nCVuumZ/2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d3eebce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts, r2s = list(zip( *tfl.r2_progress ))\n",
    "plt.plot(ts, r2s)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"R^2\")\n",
    "plt.ylim([0, 0.1* np.ceil(10*max(r2s))])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X, test_Y = X[trainsamples:(2*trainsamples+1)], y[trainsamples:(2*trainsamples+1)].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.4243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading a session\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28037887863227906"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfl = tflasso(checkpoint_dir = \"./cnn_ckpt/\")\n",
    "tfl.transform( test_X, test_Y, load = True)\n",
    "\n",
    "print( tfl.loss )\n",
    "r2 = 1- tfl.loss/test_Y.var()\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading a session\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tfl._create_network()\n",
    "    sess_config = tf.ConfigProto(inter_op_parallelism_threads=1,\n",
    "                               intra_op_parallelism_threads= 1)\n",
    "    with tf.Session(config = sess_config) as sess:\n",
    "        ckpt = tfl._load_(sess)\n",
    "        \n",
    "        print( int(ckpt.all_model_checkpoint_paths[-1].split(\"-\")[-1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckpt.all_model_checkpoint_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf3.powers_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "ncoef = len(W1)\n",
    "xlabels = np.array( get_labels(pf3) )\n",
    "\n",
    "forder = np.array([len(x) for x in xlabels])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3,figsize = (14, 5))\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "for nn in range(3):\n",
    "    valid =( forder == (nn+1))\n",
    "    print(sum(valid))\n",
    "    x_ =  np.arange(ncoef)[valid]\n",
    "    y_ = np.log10( abs(W1[valid]) )\n",
    "    axs[nn].scatter(x_, y_ )\n",
    "    axs[nn].scatter( x_[y_>-3], y_[y_>-3], 25, \"r\" )\n",
    "    #axs[nn].stem( x_[y_>-3], y_[y_>-3], markerfmt = \"ro\" )\n",
    "    if nn < 2:\n",
    "        axs[nn].set_xticks(x_ )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid]], rotation = 90)\n",
    "    else:\n",
    "        axs[nn].set_xticks(x_[::4] )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid][::4]], rotation = 90)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "print(len(W1))\n",
    "plt.stem( np.arange(len(W1)), np.log10( abs(W1)) )\n",
    "plt.stem( np.arange(len(W1))[np.log10(W1)>-3], np.log10(W1)[np.log10(W1)>-3], markerfmt = \"ro\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "10 + 10*11/2 + 10*11*12/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfl.fit( train_X, train_Y , load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfl.fit( train_X, train_Y , load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"\"\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "NUM_CORES = 3  # Choose how many cores to use.\n",
    "sess_config = tf.ConfigProto(inter_op_parallelism_threads=NUM_CORES,\n",
    "                                                   intra_op_parallelism_threads=NUM_CORES)\n",
    "with tf.Session(config= sess_config) as sess:\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt.model_checkpoint_path  = './model.ckpt-1300'\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        raise Exception(\"...no checkpoint found...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
