{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer)\n",
    "    return var\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "    Note that the Variable is initialized with a truncated normal distribution.\n",
    "    A weight decay is added only if one is specified.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    var = _variable_on_cpu(name, shape,\n",
    "                         tf.truncated_normal_initializer(stddev=stddev))\n",
    "    if wd:\n",
    "        weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tflearn import tflearn, vardict\n",
    "\n",
    "class tflasso(tflearn):\n",
    "    def _create_network(self):\n",
    "        c1d = 32\n",
    "        c2d = 16\n",
    "        self.vars = vardict()\n",
    "        self.vars.xx = tf.placeholder(\"float\", shape=[None, self.xlen])\n",
    "        self.vars.yy = tf.placeholder(\"float\", shape=[None, 1])\n",
    "\n",
    "        #def fully_connected():\n",
    "            \n",
    "        # Create Model\n",
    "        x_images = tf.reshape(self.vars.xx, [-1, 1, self.xlen//2,2])\n",
    "        # print(\"x_images\", x_images.get_shape())\n",
    "        \n",
    "        with tf.variable_scope('conv1') as scope:\n",
    "            self.parameters.c1_kernel = _variable_with_weight_decay('weights', shape=[1, 5, 2, c1d],\n",
    "                                                 stddev=1e-4, wd=0.0)\n",
    "            conv = tf.nn.conv2d(x_images, self.parameters.c1_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = _variable_on_cpu('biases', [c1d], tf.constant_initializer(0.0))\n",
    "            bias = tf.nn.bias_add(conv, biases)\n",
    "            conv1 = tf.nn.relu(bias, name=scope.name)\n",
    "            #_activation_summary(conv1)\n",
    "        \n",
    "        # pool1\n",
    "        pool1 = tf.nn.max_pool(conv1, ksize=[1, 1, 3, 1], strides=[1, 1, 2, 1],\n",
    "                                 padding='SAME', name='pool1')\n",
    "        # norm1\n",
    "        norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha= 1e-5, beta=0.75,\n",
    "                            name='norm1')\n",
    "        # conv2\n",
    "        with tf.variable_scope('conv2') as scope:\n",
    "            self.parameters.c2_kernel = _variable_with_weight_decay('weights', shape=[1, 5, c1d, c2d],\n",
    "                                                 stddev=1e-4, wd=0.0)\n",
    "            conv = tf.nn.conv2d(norm1, self.parameters.c2_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = _variable_on_cpu('biases', [c2d], tf.constant_initializer(0.1))\n",
    "            bias = tf.nn.bias_add(conv, biases)\n",
    "            conv2 = tf.nn.relu(bias, name=scope.name)\n",
    "            #_activation_summary(conv2)\n",
    "        # norm2\n",
    "        norm2 = tf.nn.lrn(conv2, 4, bias=1.0,  alpha= 1e-5, beta=0.75,\n",
    "                            name='norm2')\n",
    "        # pool2\n",
    "        pool2 = tf.nn.max_pool(norm2, ksize=[1, 1, 3, 1],\n",
    "                                strides=[1, 1, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "        # local3\n",
    "        with tf.variable_scope('local3') as scope:\n",
    "            # Move everything into depth so we can perform a single matrix multiply.\n",
    "            dim = 1\n",
    "            for d in pool2.get_shape()[1:].as_list():\n",
    "                dim *= d\n",
    "            reshape = tf.reshape(pool2, [-1, dim])\n",
    "            self.parameters.l1_weights = _variable_with_weight_decay('weights', shape=[dim, self.xlen],\n",
    "                                                  stddev=1e-3, wd=0.0004)\n",
    "            self.parameters.l1_biases = _variable_on_cpu('biases', [self.xlen], tf.constant_initializer(0.1))\n",
    "            local3 = tf.nn.relu_layer(reshape, self.parameters.l1_weights, \n",
    "                                      self.parameters.l1_biases, name=scope.name)\n",
    "            #_activation_summary(local3)\n",
    "            \n",
    "        if self.train:\n",
    "            self.vars.keep_prob = tf.placeholder(\"float\")\n",
    "            local3 = tf.nn.dropout(local3, self.vars.keep_prob)\n",
    "        \n",
    "        # local4\n",
    "        with tf.variable_scope('local4') as scope:\n",
    "            self.parameters.l2_weights = _variable_with_weight_decay('weights', shape=[self.xlen, 1],\n",
    "                                                  stddev=0.04, wd=0.004)\n",
    "            self.parameters.l2_biases = _variable_on_cpu('biases', [1], tf.constant_initializer(0.1))\n",
    "            \n",
    "            self.vars.y_predicted = tf.nn.relu_layer(local3, self.parameters.l2_weights,\n",
    "                                                     self.parameters.l2_biases, name=scope.name)\n",
    "            #_activation_summary(local4)\n",
    "\n",
    "#         self.parameters[\"W1\"] = tf.Variable(tf.truncated_normal([1, self.xlen], stddev=0.1), name=\"weight\")\n",
    "#         self.parameters[\"b1\"] = tf.Variable(tf.constant(0.1, shape=[1, 1]), name=\"bias\")\n",
    "        \n",
    "        #self.vars.y_predicted = tf.matmul( self.vars.xx, tf.transpose(self.W1)) + self.b1\n",
    "        self.saver = tf.train.Saver()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/X (Group) ''\n",
      "  children := ['axis1_label1' (Array), 'axis0_label0' (Array), 'block0_items_level0' (VLArray), 'axis0_label1' (Array), 'axis0_level0' (VLArray), 'block0_items_label0' (Array), 'axis0_level1' (Array), 'axis1_label0' (Array), 'block0_values' (Array), 'block0_items_label1' (Array), 'block0_items_level1' (Array), 'axis1_level0' (Array), 'axis1_level1' (Array)], /y (Group) ''\n",
      "  children := ['index_level1' (Array), 'index_level0' (Array), 'values' (Array), 'index_label0' (Array), 'index_label1' (Array)]]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../../data/atac_tss_800_1.h5\"\n",
    "\n",
    "with pd.HDFStore(datafile) as store:\n",
    "    print(store.groups())\n",
    "    y_ = store[\"y\"]\n",
    "    X_ = store[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41881, 322)\n",
      "(4000, 322)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" transform data \"\"\"\n",
    "sys.path.append(\"..\")\n",
    "from transform_tss import safelog, sumstrands, groupcolumns\n",
    "\n",
    "feature_step = 10\n",
    "select = None# list(feature_step * np.arange(-2,3,1))\n",
    "\n",
    "Xgr = groupcolumns(X_, step = feature_step, select = select)\n",
    "print(Xgr.shape)\n",
    "# print(Xgr.head(3))\n",
    "X, y = safelog(Xgr, y_, pseudocount=1/32)\n",
    "\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#pf3 = PolynomialFeatures(degree=3)\n",
    "#X3 = pf3.fit_transform(X)\n",
    "trainsamples = 4000\n",
    "train_X, train_Y = X[:trainsamples], y[:trainsamples].as_matrix()\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(pf):\n",
    "    return list(pf._combinations(10, degree=pf.degree,\n",
    "                          interaction_only=pf.interaction_only,\n",
    "                          include_bias = pf.include_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mcheckpoint\u001b[0m*          \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-1888400\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-50\u001b[0m*   \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-7750\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-0\u001b[0m*        \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-1888450\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-501\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-7800\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-1\u001b[0m*        \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-1888500\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-51\u001b[0m*   \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-7850\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-100\u001b[0m*      \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-37550\u001b[0m*    \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-551\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-7900\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-101\u001b[0m*      \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-37600\u001b[0m*    \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-601\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-7950\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-150\u001b[0m*      \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-37650\u001b[0m*    \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-651\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-8000\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-1888300\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-37700\u001b[0m*    \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-701\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-8050\u001b[0m*\r\n",
      "\u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-1888350\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-37750\u001b[0m*    \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-751\u001b[0m*  \u001b[00;38;5;244m\u001b[m\u001b[00;38;5;64mmodel.ckpt-8100\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls ./cnn_ckpt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X, test_Y = X[trainsamples:(2*trainsamples+1)], y[trainsamples:(2*trainsamples+1)].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading a session\n",
      "None\n",
      "no checkpoint found\n",
      "training epochs: 0 ... 5000, saving each 20' epoch\n",
      "Epoch:    1\t\n",
      "\ttrain\tloss: 17.8641\tR2: 0.4291\tL2_loss: 17.8641\n",
      "\ttest\tloss: 18.9753\tR2: 0.4171\tL2_loss: 18.9753\n",
      "Epoch:   21\t\n",
      "\ttrain\tloss: 17.6473\tR2: 0.4361\tL2_loss: 17.6473\n",
      "\ttest\tloss: 18.9291\tR2: 0.4185\tL2_loss: 18.9291\n",
      "Epoch:   41\t\n",
      "\ttrain\tloss: 17.4134\tR2: 0.4435\tL2_loss: 17.4134\n",
      "\ttest\tloss: 18.8715\tR2: 0.4202\tL2_loss: 18.8715\n",
      "Epoch:   61\t\n",
      "\ttrain\tloss: 17.4148\tR2: 0.4435\tL2_loss: 17.4148\n",
      "\ttest\tloss: 18.8714\tR2: 0.4202\tL2_loss: 18.8714\n",
      "Epoch:   81\t\n",
      "\ttrain\tloss: 17.3559\tR2: 0.4454\tL2_loss: 17.3559\n",
      "\ttest\tloss: 18.7492\tR2: 0.4240\tL2_loss: 18.7492\n",
      "Epoch:  101\t\n",
      "\ttrain\tloss: 17.3221\tR2: 0.4465\tL2_loss: 17.3221\n",
      "\ttest\tloss: 18.9136\tR2: 0.4190\tL2_loss: 18.9136\n",
      "Epoch:  121\t\n",
      "\ttrain\tloss: 17.2458\tR2: 0.4489\tL2_loss: 17.2458\n",
      "\ttest\tloss: 18.8039\tR2: 0.4223\tL2_loss: 18.8039\n",
      "Epoch:  141\t\n",
      "\ttrain\tloss: 17.2428\tR2: 0.4490\tL2_loss: 17.2428\n",
      "\ttest\tloss: 18.7997\tR2: 0.4225\tL2_loss: 18.7997\n",
      "Epoch:  161\t\n",
      "\ttrain\tloss: 17.1542\tR2: 0.4518\tL2_loss: 17.1542\n",
      "\ttest\tloss: 18.8483\tR2: 0.4210\tL2_loss: 18.8483\n",
      "Epoch:  181\t\n",
      "\ttrain\tloss: 17.1605\tR2: 0.4516\tL2_loss: 17.1605\n",
      "\ttest\tloss: 18.8856\tR2: 0.4198\tL2_loss: 18.8856\n",
      "Epoch:  201\t\n",
      "\ttrain\tloss: 17.2285\tR2: 0.4494\tL2_loss: 17.2285\n",
      "\ttest\tloss: 18.9686\tR2: 0.4173\tL2_loss: 18.9686\n",
      "Epoch:  221\t\n",
      "\ttrain\tloss: 17.1423\tR2: 0.4522\tL2_loss: 17.1423\n",
      "\ttest\tloss: 18.8247\tR2: 0.4217\tL2_loss: 18.8247\n",
      "Epoch:  241\t\n",
      "\ttrain\tloss: 17.0679\tR2: 0.4546\tL2_loss: 17.0679\n",
      "\ttest\tloss: 18.8553\tR2: 0.4207\tL2_loss: 18.8553\n",
      "Epoch:  261\t\n",
      "\ttrain\tloss: 16.9741\tR2: 0.4576\tL2_loss: 16.9741\n",
      "\ttest\tloss: 18.8522\tR2: 0.4208\tL2_loss: 18.8522\n",
      "Epoch:  281\t\n",
      "\ttrain\tloss: 17.0409\tR2: 0.4554\tL2_loss: 17.0409\n",
      "\ttest\tloss: 18.8663\tR2: 0.4204\tL2_loss: 18.8663\n",
      "Epoch:  301\t\n",
      "\ttrain\tloss: 16.9742\tR2: 0.4576\tL2_loss: 16.9742\n",
      "\ttest\tloss: 18.8928\tR2: 0.4196\tL2_loss: 18.8928\n",
      "Epoch:  321\t\n",
      "\ttrain\tloss: 17.0467\tR2: 0.4553\tL2_loss: 17.0467\n",
      "\ttest\tloss: 18.9118\tR2: 0.4190\tL2_loss: 18.9118\n",
      "Epoch:  341\t\n",
      "\ttrain\tloss: 16.9683\tR2: 0.4578\tL2_loss: 16.9683\n",
      "\ttest\tloss: 18.8732\tR2: 0.4202\tL2_loss: 18.8732\n",
      "Epoch:  361\t\n",
      "\ttrain\tloss: 16.9372\tR2: 0.4588\tL2_loss: 16.9372\n",
      "\ttest\tloss: 18.9122\tR2: 0.4190\tL2_loss: 18.9122\n",
      "Epoch:  381\t\n",
      "\ttrain\tloss: 16.9771\tR2: 0.4575\tL2_loss: 16.9771\n",
      "\ttest\tloss: 19.0076\tR2: 0.4161\tL2_loss: 19.0076\n",
      "Epoch:  401\t\n",
      "\ttrain\tloss: 16.9015\tR2: 0.4599\tL2_loss: 16.9015\n",
      "\ttest\tloss: 18.9043\tR2: 0.4192\tL2_loss: 18.9043\n",
      "Epoch:  421\t\n",
      "\ttrain\tloss: 16.8266\tR2: 0.4623\tL2_loss: 16.8266\n",
      "\ttest\tloss: 18.9864\tR2: 0.4167\tL2_loss: 18.9864\n",
      "Epoch:  441\t\n",
      "\ttrain\tloss: 16.8490\tR2: 0.4616\tL2_loss: 16.8490\n",
      "\ttest\tloss: 18.9860\tR2: 0.4167\tL2_loss: 18.9860\n",
      "Epoch:  461\t\n",
      "\ttrain\tloss: 16.8644\tR2: 0.4611\tL2_loss: 16.8644\n",
      "\ttest\tloss: 18.9239\tR2: 0.4186\tL2_loss: 18.9239\n",
      "Epoch:  481\t\n",
      "\ttrain\tloss: 16.7776\tR2: 0.4639\tL2_loss: 16.7776\n",
      "\ttest\tloss: 19.0341\tR2: 0.4153\tL2_loss: 19.0341\n",
      "Epoch:  501\t\n",
      "\ttrain\tloss: 16.7552\tR2: 0.4646\tL2_loss: 16.7552\n",
      "\ttest\tloss: 18.9646\tR2: 0.4174\tL2_loss: 18.9646\n",
      "Epoch:  521\t\n",
      "\ttrain\tloss: 16.6748\tR2: 0.4671\tL2_loss: 16.6748\n",
      "\ttest\tloss: 19.0292\tR2: 0.4154\tL2_loss: 19.0292\n",
      "Epoch:  541\t\n",
      "\ttrain\tloss: 16.7287\tR2: 0.4654\tL2_loss: 16.7287\n",
      "\ttest\tloss: 18.9481\tR2: 0.4179\tL2_loss: 18.9481\n",
      "Epoch:  561\t\n",
      "\ttrain\tloss: 16.6489\tR2: 0.4680\tL2_loss: 16.6489\n",
      "\ttest\tloss: 19.0528\tR2: 0.4147\tL2_loss: 19.0528\n",
      "Epoch:  581\t\n",
      "\ttrain\tloss: 16.5825\tR2: 0.4701\tL2_loss: 16.5825\n",
      "\ttest\tloss: 19.1614\tR2: 0.4113\tL2_loss: 19.1614\n",
      "Epoch:  601\t\n",
      "\ttrain\tloss: 16.6643\tR2: 0.4675\tL2_loss: 16.6643\n",
      "\ttest\tloss: 19.1661\tR2: 0.4112\tL2_loss: 19.1661\n",
      "Epoch:  621\t\n",
      "\ttrain\tloss: 16.5557\tR2: 0.4709\tL2_loss: 16.5557\n",
      "\ttest\tloss: 19.0907\tR2: 0.4135\tL2_loss: 19.0907\n",
      "Epoch:  641\t\n",
      "\ttrain\tloss: 16.5870\tR2: 0.4699\tL2_loss: 16.5870\n",
      "\ttest\tloss: 19.1144\tR2: 0.4128\tL2_loss: 19.1144\n",
      "Epoch:  661\t\n",
      "\ttrain\tloss: 16.5461\tR2: 0.4712\tL2_loss: 16.5461\n",
      "\ttest\tloss: 19.0815\tR2: 0.4138\tL2_loss: 19.0815\n",
      "Epoch:  681\t\n",
      "\ttrain\tloss: 16.5192\tR2: 0.4721\tL2_loss: 16.5192\n",
      "\ttest\tloss: 19.0458\tR2: 0.4149\tL2_loss: 19.0458\n",
      "Epoch:  701\t\n",
      "\ttrain\tloss: 16.4644\tR2: 0.4739\tL2_loss: 16.4644\n",
      "\ttest\tloss: 19.1862\tR2: 0.4106\tL2_loss: 19.1862\n",
      "Epoch:  721\t\n",
      "\ttrain\tloss: 16.5879\tR2: 0.4699\tL2_loss: 16.5879\n",
      "\ttest\tloss: 19.2135\tR2: 0.4097\tL2_loss: 19.2135\n",
      "Epoch:  741\t\n",
      "\ttrain\tloss: 16.3329\tR2: 0.4781\tL2_loss: 16.3329\n",
      "\ttest\tloss: 19.1646\tR2: 0.4112\tL2_loss: 19.1646\n",
      "Epoch:  761\t\n",
      "\ttrain\tloss: 16.4316\tR2: 0.4749\tL2_loss: 16.4316\n",
      "\ttest\tloss: 19.1168\tR2: 0.4127\tL2_loss: 19.1168\n",
      "Epoch:  781\t\n",
      "\ttrain\tloss: 16.4248\tR2: 0.4751\tL2_loss: 16.4248\n",
      "\ttest\tloss: 19.2055\tR2: 0.4100\tL2_loss: 19.2055\n",
      "Epoch:  801\t\n",
      "\ttrain\tloss: 16.3580\tR2: 0.4773\tL2_loss: 16.3580\n",
      "\ttest\tloss: 19.1220\tR2: 0.4126\tL2_loss: 19.1220\n",
      "Epoch:  821\t\n",
      "\ttrain\tloss: 16.2731\tR2: 0.4800\tL2_loss: 16.2731\n",
      "\ttest\tloss: 19.0458\tR2: 0.4149\tL2_loss: 19.0458\n",
      "Epoch:  841\t\n",
      "\ttrain\tloss: 16.2937\tR2: 0.4793\tL2_loss: 16.2937\n",
      "\ttest\tloss: 19.2195\tR2: 0.4096\tL2_loss: 19.2195\n",
      "Epoch:  861\t\n",
      "\ttrain\tloss: 16.2729\tR2: 0.4800\tL2_loss: 16.2729\n",
      "\ttest\tloss: 19.2840\tR2: 0.4076\tL2_loss: 19.2840\n",
      "Epoch:  881\t\n",
      "\ttrain\tloss: 16.2386\tR2: 0.4811\tL2_loss: 16.2386\n",
      "\ttest\tloss: 19.3217\tR2: 0.4064\tL2_loss: 19.3217\n",
      "Epoch:  901\t\n",
      "\ttrain\tloss: 16.1731\tR2: 0.4832\tL2_loss: 16.1731\n",
      "\ttest\tloss: 19.2268\tR2: 0.4093\tL2_loss: 19.2268\n",
      "Epoch:  921\t\n",
      "\ttrain\tloss: 16.1961\tR2: 0.4824\tL2_loss: 16.1961\n",
      "\ttest\tloss: 19.3132\tR2: 0.4067\tL2_loss: 19.3132\n",
      "Epoch:  941\t\n",
      "\ttrain\tloss: 16.1896\tR2: 0.4826\tL2_loss: 16.1896\n",
      "\ttest\tloss: 19.3427\tR2: 0.4058\tL2_loss: 19.3427\n",
      "Epoch:  961\t\n",
      "\ttrain\tloss: 16.2081\tR2: 0.4821\tL2_loss: 16.2081\n",
      "\ttest\tloss: 19.2987\tR2: 0.4071\tL2_loss: 19.2987\n",
      "Epoch:  981\t\n",
      "\ttrain\tloss: 16.0723\tR2: 0.4864\tL2_loss: 16.0723\n",
      "\ttest\tloss: 19.4721\tR2: 0.4018\tL2_loss: 19.4721\n",
      "Epoch: 1001\t\n",
      "\ttrain\tloss: 15.9563\tR2: 0.4901\tL2_loss: 15.9563\n",
      "\ttest\tloss: 19.2781\tR2: 0.4078\tL2_loss: 19.2781\n",
      "Epoch: 1021\t\n",
      "\ttrain\tloss: 15.9972\tR2: 0.4888\tL2_loss: 15.9972\n",
      "\ttest\tloss: 19.2850\tR2: 0.4075\tL2_loss: 19.2850\n",
      "Epoch: 1041\t\n",
      "\ttrain\tloss: 16.0220\tR2: 0.4880\tL2_loss: 16.0220\n",
      "\ttest\tloss: 19.3486\tR2: 0.4056\tL2_loss: 19.3486\n",
      "Epoch: 1061\t\n",
      "\ttrain\tloss: 15.9900\tR2: 0.4890\tL2_loss: 15.9900\n",
      "\ttest\tloss: 19.3329\tR2: 0.4061\tL2_loss: 19.3329\n",
      "Epoch: 1081\t\n",
      "\ttrain\tloss: 16.0531\tR2: 0.4870\tL2_loss: 16.0531\n",
      "\ttest\tloss: 19.2774\tR2: 0.4078\tL2_loss: 19.2774\n",
      "Epoch: 1101\t\n",
      "\ttrain\tloss: 16.0195\tR2: 0.4881\tL2_loss: 16.0195\n",
      "\ttest\tloss: 19.3602\tR2: 0.4052\tL2_loss: 19.3602\n",
      "Epoch: 1121\t\n",
      "\ttrain\tloss: 15.9148\tR2: 0.4914\tL2_loss: 15.9148\n",
      "\ttest\tloss: 19.4540\tR2: 0.4024\tL2_loss: 19.4540\n",
      "Epoch: 1141\t\n",
      "\ttrain\tloss: 15.9070\tR2: 0.4917\tL2_loss: 15.9070\n",
      "\ttest\tloss: 19.3375\tR2: 0.4059\tL2_loss: 19.3375\n",
      "Epoch: 1161\t\n",
      "\ttrain\tloss: 15.8840\tR2: 0.4924\tL2_loss: 15.8840\n",
      "\ttest\tloss: 19.4689\tR2: 0.4019\tL2_loss: 19.4689\n",
      "Epoch: 1181\t\n",
      "\ttrain\tloss: 15.9449\tR2: 0.4905\tL2_loss: 15.9449\n",
      "\ttest\tloss: 19.5915\tR2: 0.3981\tL2_loss: 19.5915\n",
      "Epoch: 1201\t\n",
      "\ttrain\tloss: 15.8970\tR2: 0.4920\tL2_loss: 15.8970\n",
      "\ttest\tloss: 19.4808\tR2: 0.4015\tL2_loss: 19.4808\n",
      "Epoch: 1221\t\n",
      "\ttrain\tloss: 15.8538\tR2: 0.4934\tL2_loss: 15.8538\n",
      "\ttest\tloss: 19.3958\tR2: 0.4041\tL2_loss: 19.3958\n",
      "Epoch: 1241\t\n",
      "\ttrain\tloss: 15.8188\tR2: 0.4945\tL2_loss: 15.8188\n",
      "\ttest\tloss: 19.5290\tR2: 0.4000\tL2_loss: 19.5290\n",
      "Epoch: 1261\t\n",
      "\ttrain\tloss: 15.8477\tR2: 0.4936\tL2_loss: 15.8477\n",
      "\ttest\tloss: 19.5151\tR2: 0.4005\tL2_loss: 19.5151\n",
      "Epoch: 1281\t\n",
      "\ttrain\tloss: 15.8700\tR2: 0.4929\tL2_loss: 15.8700\n",
      "\ttest\tloss: 19.6220\tR2: 0.3972\tL2_loss: 19.6220\n",
      "Epoch: 1301\t\n",
      "\ttrain\tloss: 15.7749\tR2: 0.4959\tL2_loss: 15.7749\n",
      "\ttest\tloss: 19.5011\tR2: 0.4009\tL2_loss: 19.5011\n",
      "Epoch: 1321\t\n",
      "\ttrain\tloss: 15.6830\tR2: 0.4988\tL2_loss: 15.6830\n",
      "\ttest\tloss: 19.5545\tR2: 0.3993\tL2_loss: 19.5545\n",
      "Epoch: 1341\t\n",
      "\ttrain\tloss: 15.8330\tR2: 0.4940\tL2_loss: 15.8330\n",
      "\ttest\tloss: 19.5021\tR2: 0.4009\tL2_loss: 19.5021\n",
      "Epoch: 1361\t\n",
      "\ttrain\tloss: 15.7735\tR2: 0.4959\tL2_loss: 15.7735\n",
      "\ttest\tloss: 19.5447\tR2: 0.3996\tL2_loss: 19.5447\n",
      "Epoch: 1381\t\n",
      "\ttrain\tloss: 15.7062\tR2: 0.4981\tL2_loss: 15.7062\n",
      "\ttest\tloss: 19.6715\tR2: 0.3957\tL2_loss: 19.6715\n",
      "Epoch: 1401\t\n",
      "\ttrain\tloss: 15.6801\tR2: 0.4989\tL2_loss: 15.6801\n",
      "\ttest\tloss: 19.4629\tR2: 0.4021\tL2_loss: 19.4629\n",
      "Epoch: 1421\t\n",
      "\ttrain\tloss: 15.7125\tR2: 0.4979\tL2_loss: 15.7125\n",
      "\ttest\tloss: 19.7127\tR2: 0.3944\tL2_loss: 19.7127\n",
      "Epoch: 1441\t\n",
      "\ttrain\tloss: 15.6026\tR2: 0.5014\tL2_loss: 15.6026\n",
      "\ttest\tloss: 19.6514\tR2: 0.3963\tL2_loss: 19.6514\n",
      "Epoch: 1461\t\n",
      "\ttrain\tloss: 15.6129\tR2: 0.5011\tL2_loss: 15.6129\n",
      "\ttest\tloss: 19.5478\tR2: 0.3995\tL2_loss: 19.5478\n",
      "Epoch: 1481\t\n",
      "\ttrain\tloss: 15.5614\tR2: 0.5027\tL2_loss: 15.5614\n",
      "\ttest\tloss: 19.7558\tR2: 0.3931\tL2_loss: 19.7558\n",
      "Epoch: 1501\t\n",
      "\ttrain\tloss: 15.6021\tR2: 0.5014\tL2_loss: 15.6021\n",
      "\ttest\tloss: 19.8104\tR2: 0.3914\tL2_loss: 19.8104\n",
      "Epoch: 1521\t\n",
      "\ttrain\tloss: 15.5341\tR2: 0.5036\tL2_loss: 15.5341\n",
      "\ttest\tloss: 19.5301\tR2: 0.4000\tL2_loss: 19.5301\n",
      "Epoch: 1541\t\n",
      "\ttrain\tloss: 15.5614\tR2: 0.5027\tL2_loss: 15.5614\n",
      "\ttest\tloss: 19.6767\tR2: 0.3955\tL2_loss: 19.6767\n",
      "Epoch: 1561\t\n",
      "\ttrain\tloss: 15.5480\tR2: 0.5031\tL2_loss: 15.5480\n",
      "\ttest\tloss: 19.6067\tR2: 0.3977\tL2_loss: 19.6067\n",
      "Epoch: 1581\t\n",
      "\ttrain\tloss: 15.4717\tR2: 0.5056\tL2_loss: 15.4717\n",
      "\ttest\tloss: 19.4925\tR2: 0.4012\tL2_loss: 19.4925\n",
      "Epoch: 1601\t\n",
      "\ttrain\tloss: 15.4075\tR2: 0.5076\tL2_loss: 15.4075\n",
      "\ttest\tloss: 19.6032\tR2: 0.3978\tL2_loss: 19.6032\n",
      "Epoch: 1621\t\n",
      "\ttrain\tloss: 15.4932\tR2: 0.5049\tL2_loss: 15.4932\n",
      "\ttest\tloss: 19.6078\tR2: 0.3976\tL2_loss: 19.6078\n",
      "Epoch: 1641\t\n",
      "\ttrain\tloss: 15.5341\tR2: 0.5036\tL2_loss: 15.5341\n",
      "\ttest\tloss: 19.7626\tR2: 0.3929\tL2_loss: 19.7626\n",
      "Epoch: 1661\t\n",
      "\ttrain\tloss: 15.4072\tR2: 0.5076\tL2_loss: 15.4072\n",
      "\ttest\tloss: 19.6145\tR2: 0.3974\tL2_loss: 19.6145\n",
      "Epoch: 1681\t\n",
      "\ttrain\tloss: 15.3502\tR2: 0.5095\tL2_loss: 15.3502\n",
      "\ttest\tloss: 19.6724\tR2: 0.3956\tL2_loss: 19.6724\n",
      "Epoch: 1701\t\n",
      "\ttrain\tloss: 15.4124\tR2: 0.5075\tL2_loss: 15.4124\n",
      "\ttest\tloss: 19.8386\tR2: 0.3905\tL2_loss: 19.8386\n",
      "Epoch: 1721\t\n",
      "\ttrain\tloss: 15.4001\tR2: 0.5079\tL2_loss: 15.4001\n",
      "\ttest\tloss: 19.7720\tR2: 0.3926\tL2_loss: 19.7720\n",
      "Epoch: 1741\t\n",
      "\ttrain\tloss: 15.4146\tR2: 0.5074\tL2_loss: 15.4146\n",
      "\ttest\tloss: 19.7215\tR2: 0.3941\tL2_loss: 19.7215\n",
      "Epoch: 1761\t\n",
      "\ttrain\tloss: 15.4286\tR2: 0.5070\tL2_loss: 15.4286\n",
      "\ttest\tloss: 19.9137\tR2: 0.3882\tL2_loss: 19.9137\n",
      "Epoch: 1781\t\n",
      "\ttrain\tloss: 15.4067\tR2: 0.5077\tL2_loss: 15.4067\n",
      "\ttest\tloss: 19.6915\tR2: 0.3951\tL2_loss: 19.6915\n",
      "Epoch: 1801\t\n",
      "\ttrain\tloss: 15.3839\tR2: 0.5084\tL2_loss: 15.3839\n",
      "\ttest\tloss: 19.7906\tR2: 0.3920\tL2_loss: 19.7906\n",
      "Epoch: 1821\t\n",
      "\ttrain\tloss: 15.2826\tR2: 0.5116\tL2_loss: 15.2826\n",
      "\ttest\tloss: 19.8591\tR2: 0.3899\tL2_loss: 19.8591\n",
      "Epoch: 1841\t\n",
      "\ttrain\tloss: 15.3225\tR2: 0.5104\tL2_loss: 15.3225\n",
      "\ttest\tloss: 19.8610\tR2: 0.3898\tL2_loss: 19.8610\n",
      "Epoch: 1861\t\n",
      "\ttrain\tloss: 15.3058\tR2: 0.5109\tL2_loss: 15.3058\n",
      "\ttest\tloss: 19.9093\tR2: 0.3884\tL2_loss: 19.9093\n",
      "Epoch: 1881\t\n",
      "\ttrain\tloss: 15.3115\tR2: 0.5107\tL2_loss: 15.3115\n",
      "\ttest\tloss: 19.7948\tR2: 0.3919\tL2_loss: 19.7948\n",
      "Epoch: 1901\t\n",
      "\ttrain\tloss: 15.3218\tR2: 0.5104\tL2_loss: 15.3218\n",
      "\ttest\tloss: 19.8778\tR2: 0.3893\tL2_loss: 19.8778\n",
      "Epoch: 1921\t\n",
      "\ttrain\tloss: 15.2597\tR2: 0.5124\tL2_loss: 15.2597\n",
      "\ttest\tloss: 19.9787\tR2: 0.3862\tL2_loss: 19.9787\n",
      "Epoch: 1941\t\n",
      "\ttrain\tloss: 15.2335\tR2: 0.5132\tL2_loss: 15.2335\n",
      "\ttest\tloss: 19.8688\tR2: 0.3896\tL2_loss: 19.8688\n",
      "Epoch: 1961\t\n",
      "\ttrain\tloss: 15.2441\tR2: 0.5129\tL2_loss: 15.2441\n",
      "\ttest\tloss: 20.0556\tR2: 0.3839\tL2_loss: 20.0556\n",
      "Epoch: 1981\t\n",
      "\ttrain\tloss: 15.2057\tR2: 0.5141\tL2_loss: 15.2057\n",
      "\ttest\tloss: 19.8410\tR2: 0.3905\tL2_loss: 19.8410\n",
      "Epoch: 2001\t\n",
      "\ttrain\tloss: 15.2165\tR2: 0.5137\tL2_loss: 15.2165\n",
      "\ttest\tloss: 19.9072\tR2: 0.3884\tL2_loss: 19.9072\n",
      "Epoch: 2021\t\n",
      "\ttrain\tloss: 15.1880\tR2: 0.5147\tL2_loss: 15.1880\n",
      "\ttest\tloss: 19.7395\tR2: 0.3936\tL2_loss: 19.7395\n",
      "Epoch: 2041\t\n",
      "\ttrain\tloss: 15.1951\tR2: 0.5144\tL2_loss: 15.1951\n",
      "\ttest\tloss: 20.0211\tR2: 0.3849\tL2_loss: 20.0211\n",
      "Epoch: 2061\t\n",
      "\ttrain\tloss: 15.1744\tR2: 0.5151\tL2_loss: 15.1744\n",
      "\ttest\tloss: 19.9692\tR2: 0.3865\tL2_loss: 19.9692\n",
      "Epoch: 2081\t\n",
      "\ttrain\tloss: 15.1226\tR2: 0.5167\tL2_loss: 15.1226\n",
      "\ttest\tloss: 19.6792\tR2: 0.3954\tL2_loss: 19.6792\n",
      "Epoch: 2101\t\n",
      "\ttrain\tloss: 15.0397\tR2: 0.5194\tL2_loss: 15.0397\n",
      "\ttest\tloss: 19.9093\tR2: 0.3884\tL2_loss: 19.9093\n",
      "Epoch: 2121\t\n",
      "\ttrain\tloss: 15.0869\tR2: 0.5179\tL2_loss: 15.0869\n",
      "\ttest\tloss: 19.7476\tR2: 0.3933\tL2_loss: 19.7476\n",
      "Epoch: 2141\t\n",
      "\ttrain\tloss: 15.0746\tR2: 0.5183\tL2_loss: 15.0746\n",
      "\ttest\tloss: 19.9224\tR2: 0.3880\tL2_loss: 19.9224\n",
      "Epoch: 2161\t\n",
      "\ttrain\tloss: 15.1159\tR2: 0.5170\tL2_loss: 15.1159\n",
      "\ttest\tloss: 20.0479\tR2: 0.3841\tL2_loss: 20.0479\n",
      "Epoch: 2181\t\n",
      "\ttrain\tloss: 15.0246\tR2: 0.5199\tL2_loss: 15.0246\n",
      "\ttest\tloss: 19.8969\tR2: 0.3887\tL2_loss: 19.8969\n",
      "Epoch: 2201\t\n",
      "\ttrain\tloss: 15.0591\tR2: 0.5188\tL2_loss: 15.0591\n",
      "\ttest\tloss: 19.9584\tR2: 0.3869\tL2_loss: 19.9584\n",
      "Epoch: 2221\t\n",
      "\ttrain\tloss: 14.9883\tR2: 0.5210\tL2_loss: 14.9883\n",
      "\ttest\tloss: 19.9959\tR2: 0.3857\tL2_loss: 19.9959\n",
      "Epoch: 2241\t\n",
      "\ttrain\tloss: 15.1111\tR2: 0.5171\tL2_loss: 15.1111\n",
      "\ttest\tloss: 20.0979\tR2: 0.3826\tL2_loss: 20.0979\n",
      "Epoch: 2261\t\n",
      "\ttrain\tloss: 15.0138\tR2: 0.5202\tL2_loss: 15.0138\n",
      "\ttest\tloss: 19.8772\tR2: 0.3894\tL2_loss: 19.8772\n",
      "Epoch: 2281\t\n",
      "\ttrain\tloss: 14.9981\tR2: 0.5207\tL2_loss: 14.9981\n",
      "\ttest\tloss: 19.9723\tR2: 0.3864\tL2_loss: 19.9723\n",
      "Epoch: 2301\t\n",
      "\ttrain\tloss: 15.0619\tR2: 0.5187\tL2_loss: 15.0619\n",
      "\ttest\tloss: 20.0045\tR2: 0.3854\tL2_loss: 20.0045\n",
      "Epoch: 2321\t\n",
      "\ttrain\tloss: 14.9792\tR2: 0.5213\tL2_loss: 14.9792\n",
      "\ttest\tloss: 20.1036\tR2: 0.3824\tL2_loss: 20.1036\n",
      "Epoch: 2341\t\n",
      "\ttrain\tloss: 14.9351\tR2: 0.5227\tL2_loss: 14.9351\n",
      "\ttest\tloss: 19.9330\tR2: 0.3876\tL2_loss: 19.9330\n",
      "Epoch: 2361\t\n",
      "\ttrain\tloss: 15.0306\tR2: 0.5197\tL2_loss: 15.0306\n",
      "\ttest\tloss: 19.9518\tR2: 0.3871\tL2_loss: 19.9518\n",
      "Epoch: 2381\t\n",
      "\ttrain\tloss: 14.9670\tR2: 0.5217\tL2_loss: 14.9670\n",
      "\ttest\tloss: 20.1093\tR2: 0.3822\tL2_loss: 20.1093\n",
      "Epoch: 2401\t\n",
      "\ttrain\tloss: 14.8628\tR2: 0.5250\tL2_loss: 14.8628\n",
      "\ttest\tloss: 20.0620\tR2: 0.3837\tL2_loss: 20.0620\n",
      "Epoch: 2421\t\n",
      "\ttrain\tloss: 14.9996\tR2: 0.5207\tL2_loss: 14.9996\n",
      "\ttest\tloss: 20.0787\tR2: 0.3832\tL2_loss: 20.0787\n",
      "Epoch: 2441\t\n",
      "\ttrain\tloss: 14.8457\tR2: 0.5256\tL2_loss: 14.8457\n",
      "\ttest\tloss: 20.1643\tR2: 0.3805\tL2_loss: 20.1643\n",
      "Epoch: 2461\t\n",
      "\ttrain\tloss: 14.8912\tR2: 0.5241\tL2_loss: 14.8912\n",
      "\ttest\tloss: 20.1336\tR2: 0.3815\tL2_loss: 20.1336\n",
      "Epoch: 2481\t\n",
      "\ttrain\tloss: 14.8541\tR2: 0.5253\tL2_loss: 14.8541\n",
      "\ttest\tloss: 20.0510\tR2: 0.3840\tL2_loss: 20.0510\n",
      "Epoch: 2501\t\n",
      "\ttrain\tloss: 14.8231\tR2: 0.5263\tL2_loss: 14.8231\n",
      "\ttest\tloss: 20.0737\tR2: 0.3833\tL2_loss: 20.0737\n",
      "Epoch: 2521\t\n",
      "\ttrain\tloss: 14.7969\tR2: 0.5271\tL2_loss: 14.7969\n",
      "\ttest\tloss: 20.1110\tR2: 0.3822\tL2_loss: 20.1110\n",
      "Epoch: 2541\t\n",
      "\ttrain\tloss: 14.8219\tR2: 0.5263\tL2_loss: 14.8219\n",
      "\ttest\tloss: 20.0576\tR2: 0.3838\tL2_loss: 20.0576\n",
      "Epoch: 2561\t\n",
      "\ttrain\tloss: 14.8023\tR2: 0.5270\tL2_loss: 14.8023\n",
      "\ttest\tloss: 20.2813\tR2: 0.3769\tL2_loss: 20.2813\n",
      "Epoch: 2581\t\n",
      "\ttrain\tloss: 14.7348\tR2: 0.5291\tL2_loss: 14.7348\n",
      "\ttest\tloss: 20.0576\tR2: 0.3838\tL2_loss: 20.0576\n",
      "Epoch: 2601\t\n",
      "\ttrain\tloss: 14.7639\tR2: 0.5282\tL2_loss: 14.7639\n",
      "\ttest\tloss: 20.2795\tR2: 0.3770\tL2_loss: 20.2795\n",
      "Epoch: 2621\t\n",
      "\ttrain\tloss: 14.7739\tR2: 0.5279\tL2_loss: 14.7739\n",
      "\ttest\tloss: 20.1520\tR2: 0.3809\tL2_loss: 20.1520\n",
      "Epoch: 2641\t\n",
      "\ttrain\tloss: 14.7107\tR2: 0.5299\tL2_loss: 14.7107\n",
      "\ttest\tloss: 20.3272\tR2: 0.3755\tL2_loss: 20.3272\n",
      "Epoch: 2661\t\n",
      "\ttrain\tloss: 14.7345\tR2: 0.5291\tL2_loss: 14.7345\n",
      "\ttest\tloss: 19.9765\tR2: 0.3863\tL2_loss: 19.9765\n",
      "Epoch: 2681\t\n",
      "\ttrain\tloss: 14.7287\tR2: 0.5293\tL2_loss: 14.7287\n",
      "\ttest\tloss: 20.1755\tR2: 0.3802\tL2_loss: 20.1755\n",
      "Epoch: 2701\t\n",
      "\ttrain\tloss: 14.6865\tR2: 0.5307\tL2_loss: 14.6865\n",
      "\ttest\tloss: 20.1546\tR2: 0.3808\tL2_loss: 20.1546\n",
      "Epoch: 2721\t\n",
      "\ttrain\tloss: 14.6913\tR2: 0.5305\tL2_loss: 14.6913\n",
      "\ttest\tloss: 20.2422\tR2: 0.3781\tL2_loss: 20.2422\n",
      "Epoch: 2741\t\n",
      "\ttrain\tloss: 14.7786\tR2: 0.5277\tL2_loss: 14.7786\n",
      "\ttest\tloss: 20.1499\tR2: 0.3810\tL2_loss: 20.1499\n",
      "Epoch: 2761\t\n",
      "\ttrain\tloss: 14.6299\tR2: 0.5325\tL2_loss: 14.6299\n",
      "\ttest\tloss: 20.2334\tR2: 0.3784\tL2_loss: 20.2334\n",
      "Epoch: 2781\t\n",
      "\ttrain\tloss: 14.6452\tR2: 0.5320\tL2_loss: 14.6452\n",
      "\ttest\tloss: 20.2356\tR2: 0.3783\tL2_loss: 20.2356\n",
      "Epoch: 2801\t\n",
      "\ttrain\tloss: 14.6389\tR2: 0.5322\tL2_loss: 14.6389\n",
      "\ttest\tloss: 20.2561\tR2: 0.3777\tL2_loss: 20.2561\n",
      "Epoch: 2821\t\n",
      "\ttrain\tloss: 14.6062\tR2: 0.5332\tL2_loss: 14.6062\n",
      "\ttest\tloss: 20.2395\tR2: 0.3782\tL2_loss: 20.2395\n",
      "Epoch: 2841\t\n",
      "\ttrain\tloss: 14.6351\tR2: 0.5323\tL2_loss: 14.6351\n",
      "\ttest\tloss: 20.1590\tR2: 0.3807\tL2_loss: 20.1590\n",
      "Epoch: 2861\t\n",
      "\ttrain\tloss: 14.5910\tR2: 0.5337\tL2_loss: 14.5910\n",
      "\ttest\tloss: 20.2271\tR2: 0.3786\tL2_loss: 20.2271\n",
      "Epoch: 2881\t\n",
      "\ttrain\tloss: 14.6275\tR2: 0.5326\tL2_loss: 14.6275\n",
      "\ttest\tloss: 20.1616\tR2: 0.3806\tL2_loss: 20.1616\n",
      "Epoch: 2901\t\n",
      "\ttrain\tloss: 14.5884\tR2: 0.5338\tL2_loss: 14.5884\n",
      "\ttest\tloss: 20.3667\tR2: 0.3743\tL2_loss: 20.3667\n",
      "Epoch: 2921\t\n",
      "\ttrain\tloss: 14.5837\tR2: 0.5340\tL2_loss: 14.5837\n",
      "\ttest\tloss: 20.4067\tR2: 0.3731\tL2_loss: 20.4067\n",
      "Epoch: 2941\t\n",
      "\ttrain\tloss: 14.5753\tR2: 0.5342\tL2_loss: 14.5753\n",
      "\ttest\tloss: 20.3089\tR2: 0.3761\tL2_loss: 20.3089\n",
      "Epoch: 2961\t\n",
      "\ttrain\tloss: 14.5729\tR2: 0.5343\tL2_loss: 14.5729\n",
      "\ttest\tloss: 20.2440\tR2: 0.3781\tL2_loss: 20.2440\n",
      "Epoch: 2981\t\n",
      "\ttrain\tloss: 14.5761\tR2: 0.5342\tL2_loss: 14.5761\n",
      "\ttest\tloss: 20.3232\tR2: 0.3756\tL2_loss: 20.3232\n",
      "Epoch: 3001\t\n",
      "\ttrain\tloss: 14.5691\tR2: 0.5344\tL2_loss: 14.5691\n",
      "\ttest\tloss: 20.1962\tR2: 0.3796\tL2_loss: 20.1962\n",
      "Epoch: 3021\t\n",
      "\ttrain\tloss: 14.5160\tR2: 0.5361\tL2_loss: 14.5160\n",
      "\ttest\tloss: 20.2220\tR2: 0.3788\tL2_loss: 20.2220\n",
      "Epoch: 3041\t\n",
      "\ttrain\tloss: 14.4662\tR2: 0.5377\tL2_loss: 14.4662\n",
      "\ttest\tloss: 20.4523\tR2: 0.3717\tL2_loss: 20.4523\n",
      "Epoch: 3061\t\n",
      "\ttrain\tloss: 14.4782\tR2: 0.5373\tL2_loss: 14.4782\n",
      "\ttest\tloss: 20.2341\tR2: 0.3784\tL2_loss: 20.2341\n",
      "Epoch: 3081\t\n",
      "\ttrain\tloss: 14.4595\tR2: 0.5379\tL2_loss: 14.4595\n",
      "\ttest\tloss: 20.3311\tR2: 0.3754\tL2_loss: 20.3311\n",
      "Epoch: 3101\t\n",
      "\ttrain\tloss: 14.5185\tR2: 0.5360\tL2_loss: 14.5185\n",
      "\ttest\tloss: 20.3860\tR2: 0.3737\tL2_loss: 20.3860\n",
      "Epoch: 3121\t\n",
      "\ttrain\tloss: 14.4958\tR2: 0.5368\tL2_loss: 14.4958\n",
      "\ttest\tloss: 20.4438\tR2: 0.3719\tL2_loss: 20.4438\n",
      "Epoch: 3141\t\n",
      "\ttrain\tloss: 14.4623\tR2: 0.5378\tL2_loss: 14.4623\n",
      "\ttest\tloss: 20.3281\tR2: 0.3755\tL2_loss: 20.3281\n",
      "Epoch: 3161\t\n",
      "\ttrain\tloss: 14.4580\tR2: 0.5380\tL2_loss: 14.4580\n",
      "\ttest\tloss: 20.3707\tR2: 0.3742\tL2_loss: 20.3707\n",
      "Epoch: 3181\t\n",
      "\ttrain\tloss: 14.4157\tR2: 0.5393\tL2_loss: 14.4157\n",
      "\ttest\tloss: 20.5396\tR2: 0.3690\tL2_loss: 20.5396\n",
      "Epoch: 3201\t\n",
      "\ttrain\tloss: 14.3591\tR2: 0.5411\tL2_loss: 14.3591\n",
      "\ttest\tloss: 20.4376\tR2: 0.3721\tL2_loss: 20.4376\n",
      "Epoch: 3221\t\n",
      "\ttrain\tloss: 14.4230\tR2: 0.5391\tL2_loss: 14.4230\n",
      "\ttest\tloss: 20.3292\tR2: 0.3755\tL2_loss: 20.3292\n",
      "Epoch: 3241\t\n",
      "\ttrain\tloss: 14.4045\tR2: 0.5397\tL2_loss: 14.4045\n",
      "\ttest\tloss: 20.4061\tR2: 0.3731\tL2_loss: 20.4061\n",
      "Epoch: 3261\t\n",
      "\ttrain\tloss: 14.3986\tR2: 0.5399\tL2_loss: 14.3986\n",
      "\ttest\tloss: 20.3037\tR2: 0.3762\tL2_loss: 20.3037\n",
      "Epoch: 3281\t\n",
      "\ttrain\tloss: 14.4182\tR2: 0.5393\tL2_loss: 14.4182\n",
      "\ttest\tloss: 20.4797\tR2: 0.3708\tL2_loss: 20.4797\n",
      "Epoch: 3301\t\n",
      "\ttrain\tloss: 14.3616\tR2: 0.5411\tL2_loss: 14.3616\n",
      "\ttest\tloss: 20.1949\tR2: 0.3796\tL2_loss: 20.1949\n",
      "Epoch: 3321\t\n",
      "\ttrain\tloss: 14.4013\tR2: 0.5398\tL2_loss: 14.4013\n",
      "\ttest\tloss: 20.2823\tR2: 0.3769\tL2_loss: 20.2823\n",
      "Epoch: 3341\t\n",
      "\ttrain\tloss: 14.3511\tR2: 0.5414\tL2_loss: 14.3511\n",
      "\ttest\tloss: 20.4582\tR2: 0.3715\tL2_loss: 20.4582\n",
      "Epoch: 3361\t\n",
      "\ttrain\tloss: 14.3102\tR2: 0.5427\tL2_loss: 14.3102\n",
      "\ttest\tloss: 20.4466\tR2: 0.3719\tL2_loss: 20.4466\n",
      "Epoch: 3381\t\n",
      "\ttrain\tloss: 14.4060\tR2: 0.5396\tL2_loss: 14.4060\n",
      "\ttest\tloss: 20.4155\tR2: 0.3728\tL2_loss: 20.4155\n",
      "Epoch: 3401\t\n",
      "\ttrain\tloss: 14.3405\tR2: 0.5417\tL2_loss: 14.3405\n",
      "\ttest\tloss: 20.3283\tR2: 0.3755\tL2_loss: 20.3283\n",
      "Epoch: 3421\t\n",
      "\ttrain\tloss: 14.3696\tR2: 0.5408\tL2_loss: 14.3696\n",
      "\ttest\tloss: 20.3668\tR2: 0.3743\tL2_loss: 20.3668\n",
      "Epoch: 3441\t\n",
      "\ttrain\tloss: 14.2874\tR2: 0.5434\tL2_loss: 14.2874\n",
      "\ttest\tloss: 20.5075\tR2: 0.3700\tL2_loss: 20.5075\n",
      "Epoch: 3461\t\n",
      "\ttrain\tloss: 14.3371\tR2: 0.5418\tL2_loss: 14.3371\n",
      "\ttest\tloss: 20.4055\tR2: 0.3731\tL2_loss: 20.4055\n",
      "Epoch: 3481\t\n",
      "\ttrain\tloss: 14.2954\tR2: 0.5432\tL2_loss: 14.2954\n",
      "\ttest\tloss: 20.5890\tR2: 0.3675\tL2_loss: 20.5890\n",
      "Epoch: 3501\t\n",
      "\ttrain\tloss: 14.3063\tR2: 0.5428\tL2_loss: 14.3063\n",
      "\ttest\tloss: 20.6078\tR2: 0.3669\tL2_loss: 20.6078\n",
      "Epoch: 3521\t\n",
      "\ttrain\tloss: 14.2385\tR2: 0.5450\tL2_loss: 14.2385\n",
      "\ttest\tloss: 20.5914\tR2: 0.3674\tL2_loss: 20.5914\n",
      "Epoch: 3541\t\n",
      "\ttrain\tloss: 14.2118\tR2: 0.5458\tL2_loss: 14.2118\n",
      "\ttest\tloss: 20.5554\tR2: 0.3685\tL2_loss: 20.5554\n",
      "Epoch: 3561\t\n",
      "\ttrain\tloss: 14.3491\tR2: 0.5415\tL2_loss: 14.3491\n",
      "\ttest\tloss: 20.5661\tR2: 0.3682\tL2_loss: 20.5661\n",
      "Epoch: 3581\t\n",
      "\ttrain\tloss: 14.3134\tR2: 0.5426\tL2_loss: 14.3134\n",
      "\ttest\tloss: 20.5529\tR2: 0.3686\tL2_loss: 20.5529\n",
      "Epoch: 3601\t\n",
      "\ttrain\tloss: 14.1444\tR2: 0.5480\tL2_loss: 14.1444\n",
      "\ttest\tloss: 20.3633\tR2: 0.3744\tL2_loss: 20.3633\n",
      "Epoch: 3621\t\n",
      "\ttrain\tloss: 14.1959\tR2: 0.5464\tL2_loss: 14.1959\n",
      "\ttest\tloss: 20.5096\tR2: 0.3699\tL2_loss: 20.5096\n",
      "Epoch: 3641\t\n",
      "\ttrain\tloss: 14.2354\tR2: 0.5451\tL2_loss: 14.2354\n",
      "\ttest\tloss: 20.5993\tR2: 0.3672\tL2_loss: 20.5993\n",
      "Epoch: 3661\t\n",
      "\ttrain\tloss: 14.1132\tR2: 0.5490\tL2_loss: 14.1132\n",
      "\ttest\tloss: 20.6529\tR2: 0.3655\tL2_loss: 20.6529\n",
      "Epoch: 3681\t\n",
      "\ttrain\tloss: 14.1961\tR2: 0.5463\tL2_loss: 14.1961\n",
      "\ttest\tloss: 20.5074\tR2: 0.3700\tL2_loss: 20.5074\n",
      "Epoch: 3701\t\n",
      "\ttrain\tloss: 14.2321\tR2: 0.5452\tL2_loss: 14.2321\n",
      "\ttest\tloss: 20.6196\tR2: 0.3665\tL2_loss: 20.6196\n",
      "Epoch: 3721\t\n",
      "\ttrain\tloss: 14.1635\tR2: 0.5474\tL2_loss: 14.1635\n",
      "\ttest\tloss: 20.4122\tR2: 0.3729\tL2_loss: 20.4122\n",
      "Epoch: 3741\t\n",
      "\ttrain\tloss: 14.2150\tR2: 0.5457\tL2_loss: 14.2150\n",
      "\ttest\tloss: 20.5527\tR2: 0.3686\tL2_loss: 20.5527\n",
      "Epoch: 3761\t\n",
      "\ttrain\tloss: 14.1951\tR2: 0.5464\tL2_loss: 14.1951\n",
      "\ttest\tloss: 20.6229\tR2: 0.3664\tL2_loss: 20.6229\n",
      "Epoch: 3781\t\n",
      "\ttrain\tloss: 14.1015\tR2: 0.5494\tL2_loss: 14.1015\n",
      "\ttest\tloss: 20.4893\tR2: 0.3705\tL2_loss: 20.4893\n",
      "Epoch: 3801\t\n",
      "\ttrain\tloss: 14.1650\tR2: 0.5473\tL2_loss: 14.1650\n",
      "\ttest\tloss: 20.5095\tR2: 0.3699\tL2_loss: 20.5095\n",
      "Epoch: 3821\t\n",
      "\ttrain\tloss: 14.1843\tR2: 0.5467\tL2_loss: 14.1843\n",
      "\ttest\tloss: 20.5906\tR2: 0.3674\tL2_loss: 20.5906\n",
      "Epoch: 3841\t\n",
      "\ttrain\tloss: 14.1599\tR2: 0.5475\tL2_loss: 14.1599\n",
      "\ttest\tloss: 20.5137\tR2: 0.3698\tL2_loss: 20.5137\n",
      "Epoch: 3861\t\n",
      "\ttrain\tloss: 14.1730\tR2: 0.5471\tL2_loss: 14.1730\n",
      "\ttest\tloss: 20.5935\tR2: 0.3673\tL2_loss: 20.5935\n",
      "Epoch: 3881\t\n",
      "\ttrain\tloss: 14.0999\tR2: 0.5494\tL2_loss: 14.0999\n",
      "\ttest\tloss: 20.5293\tR2: 0.3693\tL2_loss: 20.5293\n",
      "Epoch: 3901\t\n",
      "\ttrain\tloss: 14.1741\tR2: 0.5470\tL2_loss: 14.1741\n",
      "\ttest\tloss: 20.7385\tR2: 0.3629\tL2_loss: 20.7385\n",
      "Epoch: 3921\t\n",
      "\ttrain\tloss: 14.0307\tR2: 0.5516\tL2_loss: 14.0307\n",
      "\ttest\tloss: 20.4997\tR2: 0.3702\tL2_loss: 20.4997\n",
      "Epoch: 3941\t\n",
      "\ttrain\tloss: 14.1098\tR2: 0.5491\tL2_loss: 14.1098\n",
      "\ttest\tloss: 20.6372\tR2: 0.3660\tL2_loss: 20.6372\n",
      "Epoch: 3961\t\n",
      "\ttrain\tloss: 14.0787\tR2: 0.5501\tL2_loss: 14.0787\n",
      "\ttest\tloss: 20.6039\tR2: 0.3670\tL2_loss: 20.6039\n",
      "Epoch: 3981\t\n",
      "\ttrain\tloss: 14.0517\tR2: 0.5510\tL2_loss: 14.0517\n",
      "\ttest\tloss: 20.9252\tR2: 0.3572\tL2_loss: 20.9252\n",
      "Epoch: 4001\t\n",
      "\ttrain\tloss: 13.9826\tR2: 0.5532\tL2_loss: 13.9826\n",
      "\ttest\tloss: 20.7720\tR2: 0.3619\tL2_loss: 20.7720\n",
      "Epoch: 4021\t\n",
      "\ttrain\tloss: 13.9925\tR2: 0.5529\tL2_loss: 13.9925\n",
      "\ttest\tloss: 20.7015\tR2: 0.3640\tL2_loss: 20.7015\n",
      "Epoch: 4041\t\n",
      "\ttrain\tloss: 14.0905\tR2: 0.5497\tL2_loss: 14.0905\n",
      "\ttest\tloss: 20.6688\tR2: 0.3650\tL2_loss: 20.6688\n",
      "Epoch: 4061\t\n",
      "\ttrain\tloss: 14.0096\tR2: 0.5523\tL2_loss: 14.0096\n",
      "\ttest\tloss: 20.7544\tR2: 0.3624\tL2_loss: 20.7544\n",
      "Epoch: 4081\t\n",
      "\ttrain\tloss: 13.9783\tR2: 0.5533\tL2_loss: 13.9783\n",
      "\ttest\tloss: 20.6685\tR2: 0.3650\tL2_loss: 20.6685\n",
      "Epoch: 4101\t\n",
      "\ttrain\tloss: 14.0556\tR2: 0.5508\tL2_loss: 14.0556\n",
      "\ttest\tloss: 20.5065\tR2: 0.3700\tL2_loss: 20.5065\n",
      "Epoch: 4121\t\n",
      "\ttrain\tloss: 13.9134\tR2: 0.5554\tL2_loss: 13.9134\n",
      "\ttest\tloss: 20.9647\tR2: 0.3559\tL2_loss: 20.9647\n",
      "Epoch: 4141\t\n",
      "\ttrain\tloss: 13.9620\tR2: 0.5538\tL2_loss: 13.9620\n",
      "\ttest\tloss: 20.5932\tR2: 0.3674\tL2_loss: 20.5932\n",
      "Epoch: 4161\t\n",
      "\ttrain\tloss: 13.8750\tR2: 0.5566\tL2_loss: 13.8750\n",
      "\ttest\tloss: 20.4840\tR2: 0.3707\tL2_loss: 20.4840\n",
      "Epoch: 4181\t\n",
      "\ttrain\tloss: 13.9245\tR2: 0.5550\tL2_loss: 13.9245\n",
      "\ttest\tloss: 20.5885\tR2: 0.3675\tL2_loss: 20.5885\n",
      "Epoch: 4201\t\n",
      "\ttrain\tloss: 13.9731\tR2: 0.5535\tL2_loss: 13.9731\n",
      "\ttest\tloss: 20.7113\tR2: 0.3637\tL2_loss: 20.7113\n",
      "Epoch: 4221\t\n",
      "\ttrain\tloss: 13.9316\tR2: 0.5548\tL2_loss: 13.9316\n",
      "\ttest\tloss: 20.7181\tR2: 0.3635\tL2_loss: 20.7181\n",
      "Epoch: 4241\t\n",
      "\ttrain\tloss: 13.9487\tR2: 0.5543\tL2_loss: 13.9487\n",
      "\ttest\tloss: 20.7522\tR2: 0.3625\tL2_loss: 20.7522\n",
      "Epoch: 4261\t\n",
      "\ttrain\tloss: 13.8772\tR2: 0.5565\tL2_loss: 13.8772\n",
      "\ttest\tloss: 20.7453\tR2: 0.3627\tL2_loss: 20.7453\n",
      "Epoch: 4281\t\n",
      "\ttrain\tloss: 13.9248\tR2: 0.5550\tL2_loss: 13.9248\n",
      "\ttest\tloss: 20.4887\tR2: 0.3706\tL2_loss: 20.4887\n",
      "Epoch: 4301\t\n",
      "\ttrain\tloss: 13.9281\tR2: 0.5549\tL2_loss: 13.9281\n",
      "\ttest\tloss: 20.7143\tR2: 0.3636\tL2_loss: 20.7143\n",
      "Epoch: 4321\t\n",
      "\ttrain\tloss: 13.9043\tR2: 0.5557\tL2_loss: 13.9043\n",
      "\ttest\tloss: 20.6225\tR2: 0.3665\tL2_loss: 20.6225\n",
      "Epoch: 4341\t\n",
      "\ttrain\tloss: 13.9303\tR2: 0.5548\tL2_loss: 13.9303\n",
      "\ttest\tloss: 20.7626\tR2: 0.3622\tL2_loss: 20.7626\n",
      "Epoch: 4361\t\n",
      "\ttrain\tloss: 13.8299\tR2: 0.5580\tL2_loss: 13.8299\n",
      "\ttest\tloss: 20.7918\tR2: 0.3613\tL2_loss: 20.7918\n",
      "Epoch: 4381\t\n",
      "\ttrain\tloss: 13.8358\tR2: 0.5579\tL2_loss: 13.8358\n",
      "\ttest\tloss: 20.8704\tR2: 0.3588\tL2_loss: 20.8704\n",
      "Epoch: 4401\t\n",
      "\ttrain\tloss: 13.8543\tR2: 0.5573\tL2_loss: 13.8543\n",
      "\ttest\tloss: 20.6333\tR2: 0.3661\tL2_loss: 20.6333\n",
      "Epoch: 4421\t\n",
      "\ttrain\tloss: 13.9319\tR2: 0.5548\tL2_loss: 13.9319\n",
      "\ttest\tloss: 20.6872\tR2: 0.3645\tL2_loss: 20.6872\n",
      "Epoch: 4441\t\n",
      "\ttrain\tloss: 13.8787\tR2: 0.5565\tL2_loss: 13.8787\n",
      "\ttest\tloss: 20.7525\tR2: 0.3625\tL2_loss: 20.7525\n",
      "Epoch: 4461\t\n",
      "\ttrain\tloss: 13.8232\tR2: 0.5583\tL2_loss: 13.8232\n",
      "\ttest\tloss: 20.6393\tR2: 0.3659\tL2_loss: 20.6393\n",
      "Epoch: 4481\t\n",
      "\ttrain\tloss: 13.7914\tR2: 0.5593\tL2_loss: 13.7914\n",
      "\ttest\tloss: 20.6530\tR2: 0.3655\tL2_loss: 20.6530\n",
      "Epoch: 4501\t\n",
      "\ttrain\tloss: 13.8173\tR2: 0.5585\tL2_loss: 13.8173\n",
      "\ttest\tloss: 20.6576\tR2: 0.3654\tL2_loss: 20.6576\n",
      "Epoch: 4521\t\n",
      "\ttrain\tloss: 13.8211\tR2: 0.5583\tL2_loss: 13.8211\n",
      "\ttest\tloss: 20.8638\tR2: 0.3590\tL2_loss: 20.8638\n",
      "Epoch: 4541\t\n",
      "\ttrain\tloss: 13.8033\tR2: 0.5589\tL2_loss: 13.8033\n",
      "\ttest\tloss: 20.9027\tR2: 0.3578\tL2_loss: 20.9027\n",
      "Epoch: 4561\t\n",
      "\ttrain\tloss: 13.7787\tR2: 0.5597\tL2_loss: 13.7787\n",
      "\ttest\tloss: 21.0335\tR2: 0.3538\tL2_loss: 21.0335\n",
      "Epoch: 4581\t\n",
      "\ttrain\tloss: 13.8932\tR2: 0.5560\tL2_loss: 13.8932\n",
      "\ttest\tloss: 20.9283\tR2: 0.3571\tL2_loss: 20.9283\n",
      "Epoch: 4601\t\n",
      "\ttrain\tloss: 13.8063\tR2: 0.5588\tL2_loss: 13.8063\n",
      "\ttest\tloss: 20.7755\tR2: 0.3618\tL2_loss: 20.7755\n",
      "Epoch: 4621\t\n",
      "\ttrain\tloss: 13.8571\tR2: 0.5572\tL2_loss: 13.8571\n",
      "\ttest\tloss: 20.8099\tR2: 0.3607\tL2_loss: 20.8099\n",
      "Epoch: 4641\t\n",
      "\ttrain\tloss: 13.7875\tR2: 0.5594\tL2_loss: 13.7875\n",
      "\ttest\tloss: 20.9032\tR2: 0.3578\tL2_loss: 20.9032\n",
      "Epoch: 4661\t\n",
      "\ttrain\tloss: 13.8752\tR2: 0.5566\tL2_loss: 13.8752\n",
      "\ttest\tloss: 20.9385\tR2: 0.3567\tL2_loss: 20.9385\n",
      "Epoch: 4681\t\n",
      "\ttrain\tloss: 13.8536\tR2: 0.5573\tL2_loss: 13.8536\n",
      "\ttest\tloss: 20.5829\tR2: 0.3677\tL2_loss: 20.5829\n",
      "Epoch: 4701\t\n",
      "\ttrain\tloss: 13.7687\tR2: 0.5600\tL2_loss: 13.7687\n",
      "\ttest\tloss: 20.6323\tR2: 0.3662\tL2_loss: 20.6323\n",
      "Epoch: 4721\t\n",
      "\ttrain\tloss: 13.8283\tR2: 0.5581\tL2_loss: 13.8283\n",
      "\ttest\tloss: 20.8668\tR2: 0.3589\tL2_loss: 20.8668\n",
      "Epoch: 4741\t\n",
      "\ttrain\tloss: 13.8440\tR2: 0.5576\tL2_loss: 13.8440\n",
      "\ttest\tloss: 21.0052\tR2: 0.3547\tL2_loss: 21.0052\n",
      "Epoch: 4761\t\n",
      "\ttrain\tloss: 13.8056\tR2: 0.5588\tL2_loss: 13.8056\n",
      "\ttest\tloss: 20.9758\tR2: 0.3556\tL2_loss: 20.9758\n",
      "Epoch: 4781\t\n",
      "\ttrain\tloss: 13.7271\tR2: 0.5613\tL2_loss: 13.7271\n",
      "\ttest\tloss: 20.8907\tR2: 0.3582\tL2_loss: 20.8907\n",
      "Epoch: 4801\t\n",
      "\ttrain\tloss: 13.7676\tR2: 0.5600\tL2_loss: 13.7676\n",
      "\ttest\tloss: 20.8940\tR2: 0.3581\tL2_loss: 20.8940\n",
      "Epoch: 4821\t\n",
      "\ttrain\tloss: 13.7046\tR2: 0.5621\tL2_loss: 13.7046\n",
      "\ttest\tloss: 20.9021\tR2: 0.3579\tL2_loss: 20.9021\n",
      "Epoch: 4841\t\n",
      "\ttrain\tloss: 13.6865\tR2: 0.5626\tL2_loss: 13.6865\n",
      "\ttest\tloss: 20.6882\tR2: 0.3644\tL2_loss: 20.6882\n",
      "Epoch: 4861\t\n",
      "\ttrain\tloss: 13.6533\tR2: 0.5637\tL2_loss: 13.6533\n",
      "\ttest\tloss: 20.6991\tR2: 0.3641\tL2_loss: 20.6991\n",
      "Epoch: 4881\t\n",
      "\ttrain\tloss: 13.7140\tR2: 0.5618\tL2_loss: 13.7140\n",
      "\ttest\tloss: 20.9141\tR2: 0.3575\tL2_loss: 20.9141\n",
      "Epoch: 4901\t\n",
      "\ttrain\tloss: 13.7008\tR2: 0.5622\tL2_loss: 13.7008\n",
      "\ttest\tloss: 20.8950\tR2: 0.3581\tL2_loss: 20.8950\n",
      "Epoch: 4921\t\n",
      "\ttrain\tloss: 13.7355\tR2: 0.5611\tL2_loss: 13.7355\n",
      "\ttest\tloss: 20.7786\tR2: 0.3617\tL2_loss: 20.7786\n",
      "Epoch: 4941\t\n",
      "\ttrain\tloss: 13.6863\tR2: 0.5626\tL2_loss: 13.6863\n",
      "\ttest\tloss: 21.0003\tR2: 0.3548\tL2_loss: 21.0003\n",
      "Epoch: 4961\t\n",
      "\ttrain\tloss: 13.7341\tR2: 0.5611\tL2_loss: 13.7341\n",
      "\ttest\tloss: 20.8980\tR2: 0.3580\tL2_loss: 20.8980\n",
      "Epoch: 4981\t\n",
      "\ttrain\tloss: 13.6468\tR2: 0.5639\tL2_loss: 13.6468\n",
      "\ttest\tloss: 20.8006\tR2: 0.3610\tL2_loss: 20.8006\n",
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.2927902671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Optimization Finished!\n",
      "_ipython_display_ not found\n",
      "_repr_png_ not found\n",
      "_repr_jpeg_ not found\n",
      "_repr_markdown_ not found\n",
      "_repr_latex_ not found\n",
      "_repr_json_ not found\n",
      "_repr_html_ not found\n",
      "_repr_pdf_ not found\n",
      "_repr_svg_ not found\n",
      "_repr_javascript_ not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.tflasso at 0x7f78105ad7b8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfl = tflasso(ALPHA = 2e-1, display_step = 20, BATCH_SIZE = 80,\n",
    "             learning_rate = 2e-3, checkpoint_dir = \"./cnn_ckpt/\")\n",
    "tfl.fit(train_X, train_Y , test_X, test_Y, load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7813a3edd8>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGO8nAUCY4zxchYIjDHGy/0/FhL5xblqMiwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7813a3e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_ = [x*20 for x in range(len(tfl.test_summary))]\n",
    "plt.plot( t_, [x[\"R2\"] for x in tfl.test_summary] , \"r\")\n",
    "plt.plot( t_, [x[\"R2\"] for x in tfl.train_summary], \"g\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEPCAYAAACzwehFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUlbaz3yoRNUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd437d0b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts, r2s = list(zip( *tfl.r2_progress ))\n",
    "plt.plot(ts, r2s)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"R^2\")\n",
    "plt.ylim([0, 0.1* np.ceil(10*max(r2s))])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tflearn failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/dima/data/repos/qtl_atac_rna/skl_pipeline/src/tfregression/tflearn.py\", line 231\n",
      "    _y_ = np.reshape(_y_, [-1, 1])\n",
      "                                                         ^\n",
      "IndentationError: unindent does not match any outer indentation level\n",
      "]\n",
      "loading a session\n",
      "loss: 20.5604\tR2: 0.3684\tL2_loss: 20.5604\n"
     ]
    }
   ],
   "source": [
    "tfl = tflasso(checkpoint_dir = \"./cnn_ckpt/\", dropout = 0)\n",
    "yhat = tfl.transform( test_X, test_Y, load = True)\n",
    "\n",
    "# print( tfl.loss )\n",
    "# r2 = 1 - tfl.loss/test_Y.var()\n",
    "# r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "model_checkpoint_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading a session\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tfl._create_network()\n",
    "    sess_config = tf.ConfigProto(inter_op_parallelism_threads=1,\n",
    "                               intra_op_parallelism_threads= 1)\n",
    "    with tf.Session(config = sess_config) as sess:\n",
    "        ckpt = tfl._load_(sess)\n",
    "        \n",
    "        print( int(ckpt.all_model_checkpoint_paths[-1].split(\"-\")[-1]) )\n",
    "        pb = ckpt.ListFields()[0][0]\n",
    "        print(pb.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckpt.all_model_checkpoint_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf3.powers_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "ncoef = len(W1)\n",
    "xlabels = np.array( get_labels(pf3) )\n",
    "\n",
    "forder = np.array([len(x) for x in xlabels])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3,figsize = (14, 5))\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "for nn in range(3):\n",
    "    valid =( forder == (nn+1))\n",
    "    print(sum(valid))\n",
    "    x_ =  np.arange(ncoef)[valid]\n",
    "    y_ = np.log10( abs(W1[valid]) )\n",
    "    axs[nn].scatter(x_, y_ )\n",
    "    axs[nn].scatter( x_[y_>-3], y_[y_>-3], 25, \"r\" )\n",
    "    #axs[nn].stem( x_[y_>-3], y_[y_>-3], markerfmt = \"ro\" )\n",
    "    if nn < 2:\n",
    "        axs[nn].set_xticks(x_ )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid]], rotation = 90)\n",
    "    else:\n",
    "        axs[nn].set_xticks(x_[::4] )\n",
    "        axs[nn].set_xticklabels([repr(x) for x in xlabels[valid][::4]], rotation = 90)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tfl.get_params()[\"W1\"][0]\n",
    "print(len(W1))\n",
    "plt.stem( np.arange(len(W1)), np.log10( abs(W1)) )\n",
    "plt.stem( np.arange(len(W1))[np.log10(W1)>-3], np.log10(W1)[np.log10(W1)>-3], markerfmt = \"ro\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "10 + 10*11/2 + 10*11*12/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfl.fit( train_X, train_Y , load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfl.fit( train_X, train_Y , load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"\"\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "NUM_CORES = 3  # Choose how many cores to use.\n",
    "sess_config = tf.ConfigProto(inter_op_parallelism_threads=NUM_CORES,\n",
    "                                                   intra_op_parallelism_threads=NUM_CORES)\n",
    "with tf.Session(config= sess_config) as sess:\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt.model_checkpoint_path  = './model.ckpt-1300'\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        raise Exception(\"...no checkpoint found...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
